{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Networks with Parallel Concatenations (GoogLeNet)\n",
    "\n",
    "\n",
    "## (**Inception Blocks**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dl import tensorflow as dl\n",
    "\n",
    "class Inception(tf.keras.Model):\n",
    "    # `c1`--`c4` are the number of output channels for each path\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super().__init__()\n",
    "        # Path 1 is a single 1 x 1 convolutional layer\n",
    "        self.p1_1 = tf.keras.layers.Conv2D(c1, 1, activation='relu')\n",
    "        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3\n",
    "        # convolutional layer\n",
    "        self.p2_1 = tf.keras.layers.Conv2D(c2[0], 1, activation='relu')\n",
    "        self.p2_2 = tf.keras.layers.Conv2D(c2[1], 3, padding='same',\n",
    "                                           activation='relu')\n",
    "        # Path 3 is a 1 x 1 convolutional layer followed by a 5 x 5\n",
    "        # convolutional layer\n",
    "        self.p3_1 = tf.keras.layers.Conv2D(c3[0], 1, activation='relu')\n",
    "        self.p3_2 = tf.keras.layers.Conv2D(c3[1], 5, padding='same',\n",
    "                                           activation='relu')\n",
    "        # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1\n",
    "        # convolutional layer\n",
    "        self.p4_1 = tf.keras.layers.MaxPool2D(3, 1, padding='same')\n",
    "        self.p4_2 = tf.keras.layers.Conv2D(c4, 1, activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # Concatenate the outputs on the channel dimension\n",
    "        return tf.keras.layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "\n",
    "\n",
    "## [**GoogLeNet Model**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def b1():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, 7, strides=2, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def b2():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, 1, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(192, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 15,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def b3():\n",
    "    return tf.keras.models.Sequential([\n",
    "        Inception(64, (96, 128), (16, 32), 32),\n",
    "        Inception(128, (128, 192), (32, 96), 64),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def b4():\n",
    "    return tf.keras.Sequential([\n",
    "        Inception(192, (96, 208), (16, 48), 64),\n",
    "        Inception(160, (112, 224), (24, 64), 64),\n",
    "        Inception(128, (128, 256), (24, 64), 64),\n",
    "        Inception(112, (144, 288), (32, 64), 64),\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 23,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def b5():\n",
    "    return tf.keras.Sequential([\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        Inception(384, (192, 384), (48, 128), 128),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Flatten()])\n",
    "\n",
    "# Recall that this has to be a function that will be passed to\n",
    "# `d2l.train_ch6()` so that model building/compiling need to be within\n",
    "# `strategy.scope()` in order to utilize the CPU/GPU devices that we have\n",
    "def net():\n",
    "    return tf.keras.Sequential([\n",
    "        b1(), b2(), b3(),\n",
    "        b4(), b5(), tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "\n",
    "The GoogLeNet model is computationally complex,\n",
    "so it is not as easy to modify the number of channels as in VGG.\n",
    "\n",
    "[**To have a reasonable training time on Fashion-MNIST,\n",
    "we reduce the input height and width from 224 to 96.**]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "X = tf.random.uniform(shape=(1, 96, 96, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "## [**Training**]\n",
    "\n",
    "As before, we train our model using the Fashion-MNIST dataset.\n",
    " We transform it to $96 \\times 96$ pixel resolution\n",
    " before invoking the training procedure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = dl.load_data_fashion_mnist(batch_size, resize=96)\n",
    "dl.train_ch6(net, train_iter, test_iter, num_epochs, lr, dl.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. There are several iterations of GoogLeNet. Try to implement and run them. Some of them include the following:\n",
    "    * Add a batch normalization layer :cite:`Ioffe.Szegedy.2015`, as described\n",
    "      later in :numref:`sec_batch_norm`.\n",
    "    * Make adjustments to the Inception block\n",
    "      :cite:`Szegedy.Vanhoucke.Ioffe.ea.2016`.\n",
    "    * Use label smoothing for model regularization\n",
    "      :cite:`Szegedy.Vanhoucke.Ioffe.ea.2016`.\n",
    "    * Include it in the residual connection\n",
    "      :cite:`Szegedy.Ioffe.Vanhoucke.ea.2017`, as described later in\n",
    "      :numref:`sec_resnet`.\n",
    "1. What is the minimum image size for GoogLeNet to work?\n",
    "1. Compare the model parameter sizes of AlexNet, VGG, and NiN with GoogLeNet. How do the latter two network architectures significantly reduce the model parameter size?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
