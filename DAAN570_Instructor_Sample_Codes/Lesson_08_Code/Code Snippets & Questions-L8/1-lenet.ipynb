{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Convolutional Neural Networks (LeNet)\n",
    "\n",
    "\n",
    "\n",
    "## LeNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dl import tensorflow as dl\n",
    "\n",
    "def net():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid',\n",
    "                               padding='same'),\n",
    "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=5,\n",
    "                               activation='sigmoid'),\n",
    "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(84, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "X = tf.random.uniform((1, 28, 28, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "\n",
    "## Training\n",
    "\n",
    "Now that we have implemented the model,\n",
    "let us [**run an experiment to see how LeNet fares on Fashion-MNIST**].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = dl.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 17,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "class TrainCallback(tf.keras.callbacks.Callback):  #@save\n",
    "    \"\"\"A callback to visiualize the training progress.\"\"\"\n",
    "    def __init__(self, net, train_iter, test_iter, num_epochs, device_name):\n",
    "        self.timer = dl.Timer()\n",
    "        self.animator = dl.Animator(\n",
    "            xlabel='epoch', xlim=[1, num_epochs],\n",
    "            legend=['train loss', 'train acc', 'test acc'])\n",
    "        self.net = net\n",
    "        self.train_iter = train_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device_name = device_name\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.timer.start()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.timer.stop()\n",
    "        test_acc = self.net.evaluate(self.test_iter, verbose=0,\n",
    "                                     return_dict=True)['accuracy']\n",
    "        metrics = (logs['loss'], logs['accuracy'], test_acc)\n",
    "        self.animator.add(epoch + 1, metrics)\n",
    "        if epoch == self.num_epochs - 1:\n",
    "            batch_size = next(iter(self.train_iter))[0].shape[0]\n",
    "            num_examples = batch_size * tf.data.experimental.cardinality(\n",
    "                self.train_iter).numpy()\n",
    "            print(f'loss {metrics[0]:.3f}, train acc {metrics[1]:.3f}, '\n",
    "                  f'test acc {metrics[2]:.3f}')\n",
    "            print(f'{num_examples / self.timer.avg():.1f} examples/sec on '\n",
    "                  f'{str(self.device_name)}')\n",
    "\n",
    "#@save\n",
    "def train_ch6(net_fn, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    device_name = device._device_name\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device_name)\n",
    "    with strategy.scope():\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        net = net_fn()\n",
    "        net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    callback = TrainCallback(net, train_iter, test_iter, num_epochs,\n",
    "                             device_name)\n",
    "    net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, dl.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Replace the average pooling with maximum pooling. What happens?\n",
    "1. Try to construct a more complex network based on LeNet to improve its accuracy.\n",
    "    1. Adjust the convolution window size.\n",
    "    1. Adjust the number of output channels.\n",
    "    1. Adjust the activation function (e.g., ReLU).\n",
    "    1. Adjust the number of convolution layers.\n",
    "    1. Adjust the number of fully connected layers.\n",
    "    1. Adjust the learning rates and other training details (e.g., initialization and number of epochs.)\n",
    "1. Try out the improved network on the original MNIST dataset.\n",
    "1. Display the activations of the first and second layer of LeNet for different inputs (e.g., sweaters and coats).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
