{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Implementation of Multilayer Perceptrons from Scratch\n",
    "\n",
    "In this Jupyter we train a model to fit the the Fashion-MNIST image classification dataset. using the softmax regression activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from dl import tensorflow as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = dl.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## Initializing Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "W1 = tf.Variable(\n",
    "    tf.random.normal(shape=(num_inputs, num_hiddens), mean=0, stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros(num_hiddens))\n",
    "W2 = tf.Variable(\n",
    "    tf.random.normal(shape=(num_hiddens, num_outputs), mean=0, stddev=0.01))\n",
    "b2 = tf.Variable(tf.random.normal([num_outputs], stddev=.01))\n",
    "\n",
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "## Activation Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return tf.math.maximum(X, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = tf.reshape(X, (-1, num_inputs))\n",
    "    H = relu(tf.matmul(X, W1) + b1)\n",
    "    return tf.matmul(H, W2) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 20,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def loss(y_hat, y):\n",
    "    return tf.losses.sparse_categorical_crossentropy(y, y_hat,\n",
    "                                                     from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "num_epochs, lr = 10, 0.1\n",
    "updater = dl.Updater([W1, W2, b1, b2], lr)\n",
    "dl.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "To evaluate the learned model,\n",
    "we apply the learned model to some test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "dl.predict_ch3(net, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "## Summary\n",
    "\n",
    "* We saw that implementing a simple MLP is easy, even when done manually.\n",
    "* However, with a large number of layers, implementing MLPs from scratch can still get messy (e.g., naming and keeping track of our model's parameters).\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Change the value of the hyperparameter `num_hiddens` and see how this hyperparameter influences your results. Determine the best value of this hyperparameter, keeping all others constant.\n",
    "1. Try adding an additional hidden layer to see how it affects the results.\n",
    "1. How does changing the learning rate alter your results? Fixing the model architecture and other hyperparameters (including number of epochs), what learning rate gives you the best results?\n",
    "1. What is the best result you can get by optimizing over all the hyperparameters (learning rate, number of epochs, number of hidden layers, number of hidden units per layer) jointly?\n",
    "1. Describe why it is much more challenging to deal with multiple hyperparameters.\n",
    "1. What is the smartest strategy you can think of for structuring a search over multiple hyperparameters?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
