{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe27296",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Keras Tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658994f7-e89e-4547-86d4-31e7ee64229e",
   "metadata": {},
   "source": [
    "> Use the `Table of Content` tab to nagivate through this tutorial and activate the [line numbering option](https://stackoverflow.com/questions/49536407/show-code-line-numbers-in-jupyterlabhttps://stackoverflow.com/questions/49536407/show-code-line-numbers-in-jupyterlab) (In JupyterLab, go to menu View > Show Line Number) to display the line numbers in cells and read the commented explainations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0b143",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Deep learning is one of the major subfield of machine learning framework. Machine learning is the study of design of algorithms, inspired from the model of human brain. Deep learning is becoming more popular in data science fields like robotics, artificial intelligence(AI), audio & video recognition and image recognition. Artificial neural network is the core of deep learning methodologies. Deep learning is supported by various libraries such as TensorFlow, Mxnet, PyTorch etc., Keras is one of the most powerful and easy to use python library for creating deep learning models.\n",
    "\n",
    "Keras is based on minimal structure that provides a clean and easy way to create deep learning models based on TensorFlow or Theano. Keras is designed to quickly define deep learning models. Well, Keras is an optimal choice for deep learning applications.\n",
    "\n",
    "**Features**\n",
    "\n",
    "Keras leverages various optimization techniques to make high level neural network API easier and more performant. It supports the following features −\n",
    "\n",
    "- Consistent, simple and extensible API.\n",
    "- Minimal structure - easy to achieve the result without any frills.\n",
    "- It supports multiple platforms and backends.\n",
    "- It is user friendly framework which runs on both CPU and GPU.\n",
    "- Highly scalability of computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bca446",
   "metadata": {},
   "source": [
    "**Benefits**\n",
    "\n",
    "Keras is highly powerful and dynamic framework and comes up with the following advantages:\n",
    "\n",
    "- Larger community support.\n",
    "- Easy to test.\n",
    "- Keras neural networks are written in Python which makes things simpler.\n",
    "- Keras supports both convolution and recurrent networks.\n",
    "- Deep learning models are discrete components, so that, you can combine into many ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bc0f6",
   "metadata": {},
   "source": [
    "# Keras Framework\n",
    "\n",
    "Keras provides a complete framework to create any type of neural networks. Keras is innovative as well as very easy to learn. It supports simple neural network to very large and complex neural network model. Let us understand the architecture of Keras framework and how Keras helps in deep learning in this chapter.\n",
    "\n",
    "Architecture of Keras\n",
    "\n",
    "Core Keras API can be divided into three main categories:\n",
    "\n",
    "- Model\n",
    "- Layer\n",
    "- Core Modules\n",
    "\n",
    "In Keras, every ANN is represented by  **Keras Models**. In turn, every Keras Model is composition of  **Keras Layers**  and represents ANN layers like input, hidden layer, output layers, convolution layer, pooling layer, etc., Keras model and layer access  **Keras modules**  for activation function, loss function, regularization function, etc., Using Keras model, Keras Layer, and Keras modules, any ANN algorithm (CNN, RNN, etc.,) can be represented in a simple and efficient manner.\n",
    "\n",
    "The following diagram depicts the relationship between model, layer and core modules −\n",
    "\n",
    "![](img/Picture1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc123c-aade-4595-845d-cedcc3b674c7",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Keras ecosystem\n",
    "\n",
    "source: [Keros ecosystem](https://keras.io/getting_started/ecosystem/)\n",
    "\n",
    "The Keras project isn't limited to the **core Keras API** for building and training neural networks. It spans a wide range of related initiatives that cover every step of the machine learning workflow.\n",
    "\n",
    "## KerasTuner\n",
    "KerasTuner Documentation - KerasTuner GitHub repository\n",
    "\n",
    "KerasTuner is an easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search. Easily configure your search space with a define-by-run syntax, then leverage one of the available search algorithms to find the best hyperparameter values for your models. KerasTuner comes with Bayesian Optimization, Hyperband, and Random Search algorithms built-in, and is also designed to be easy for researchers to extend in order to experiment with new search algorithms.\n",
    "\n",
    "## KerasNLP\n",
    "KerasNLP Documentation - KerasNLP GitHub repository\n",
    "\n",
    "KerasNLP is a natural language processing library that supports users through their entire development cycle. Our workflows are built from modular components that have state-of-the-art preset weights and architectures when used out-of-the-box and are easily customizable when more control is needed. We emphasize in-graph computation for all workflows so that developers can expect easy productionization using the TensorFlow ecosystem.\n",
    "\n",
    "## AutoKeras\n",
    "AutoKeras Documentation - AutoKeras GitHub repository\n",
    "\n",
    "AutoKeras is an AutoML system based on Keras. It is developed by DATA Lab at Texas A&M University. The goal of AutoKeras is to make machine learning accessible for everyone. It provides high-level end-to-end APIs such as ImageClassifier or TextClassifier to solve machine learning problems in a few lines, as well as flexible building blocks to perform architecture search.\n",
    "\n",
    "## KerasCV\n",
    "KerasCV Documentation - KerasCV GitHub repository\n",
    "\n",
    "KerasCV is a repository of modular building blocks (layers, metrics, losses, data-augmentation) that applied computer vision engineers can leverage to quickly assemble production-grade, state-of-the-art training and inference pipelines for common use cases such as image classification, object detection, image segmentation, image data augmentation, etc.\n",
    "\n",
    "KerasCV can be understood as a horizontal extension of the Keras API: the components are new first-party Keras objects (layers, metrics, etc) that are too specialized to be added to core Keras, but that receive the same level of polish and backwards compatibility guarantees as the rest of the Keras API and that are maintained by the Keras team itself (unlike TFAddons).\n",
    "\n",
    "## TensorFlow Cloud\n",
    "Managed by the Keras team at Google, TensorFlow Cloud is a set of utilities to help you run large-scale Keras training jobs on GCP with very little configuration effort. Running your experiments on 8 or more GPUs in the cloud should be as easy as calling model.fit().\n",
    "\n",
    "## TensorFlow.js\n",
    "TensorFlow.js is TensorFlow's JavaScript runtime, capable of running TensorFlow models in the browser or on a Node.js server, both for training and inference. It natively supports loading Keras models, including the ability to fine-tune or retrain your Keras models directly in the browser.\n",
    "\n",
    "## TensorFlow Lite\n",
    "TensorFlow Lite is a runtime for efficient on-device inference that has native support for Keras models. Deploy your models on Android, iOS, or on embedded devices.\n",
    "\n",
    "## Model optimization toolkit\n",
    "The TensorFlow Model Optimization Toolkit is a set of utilities to make your inference models faster, more memory-efficient, and more power-efficient, by performing post-training weight quantization and pruning-aware training. It has native support for Keras models, and its pruning API is built directly on top on the Keras API.\n",
    "\n",
    "## TFX integration\n",
    "TFX is an end-to-end platform for deploying and maintaining production machine learning pipelines. TFX has native support for Keras models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3259a-eb7f-4bbc-8403-e1c8d354346b",
   "metadata": {},
   "source": [
    "Let us see the overview of Keras models, Keras layers and Keras modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732ce38-3b3d-43ea-b541-a6275292adca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Keras Overview\n",
    "\n",
    "## Installing Keras\n",
    "\n",
    "To use Keras, will need to have the TensorFlow package installed. [See detailed instructions](https://www.tensorflow.org/install).\n",
    "\n",
    "Once TensorFlow is installed, just import Keras via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b7fce-dbb0-47dc-b840-7ecfb678e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# or print tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39b54d-c514-4e49-a250-464e175dcafa",
   "metadata": {},
   "source": [
    "The Keras codebase is also available on GitHub at [keras-team/keras](https://github.com/keras-team/keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958756e3-be86-4b37-b730-a827e8203323",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2f385-e0b0-48c3-baf8-abd060074d23",
   "metadata": {},
   "source": [
    "**Sequential model** is basically a linear composition of Keras Layers. Sequential model is easy, minimal as well as has the ability to represent nearly all available neural networks.\n",
    "\n",
    "A simple sequential model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, \n",
    "                activation = 'relu', \n",
    "                input_shape = (784,)))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee383cc3",
   "metadata": {},
   "source": [
    "Where,\n",
    "\n",
    "- **Line 6**  imports  **Sequential**  model from Keras models\n",
    "- **Line 8**  imports  **Dense**  layer and  **Activation**  module\n",
    "- **Line 10**  create a new sequential model using  **Sequential**  API\n",
    "- **Line 13**  adds a dense layer (Dense API) with  **relu**  activation (using Activation module) function.\n",
    "- **Line 16** prints a summary of the model (aka Neural Network).\n",
    "\n",
    "> Note that the **Sequential** model exposes **Model** class to create customized models as well. Alternatively, we can use **sub-classing** concept or Keras **Functional API** to create our own complex models. These options will be covered later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d23d6-7823-46da-8419-6a4ebb14e77b",
   "metadata": {},
   "source": [
    "Many Keras functions can be written **without** passing the keyword arguments. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0449e-e812-4cfa-8e47-debd0a0f2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, 'relu', input_shape = (784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431772aa-df75-4d90-992c-5fd31f46a728",
   "metadata": {},
   "source": [
    "In this example, the key arguments `units` and `activation` are not present in the Dense function. It is recommended to include the Keyword arguments to improve the code readability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e51339",
   "metadata": {},
   "source": [
    "## Dense Layer\n",
    "\n",
    "Each Keras `layer` in the Keras `model` represent the corresponding layer (input layer, hidden layer and output layer) in the actual proposed neural network model. Keras provides a lot of pre-build layers so that any complex neural network can be easily created. Some of the important Keras layers are specified below,\n",
    "\n",
    "- Core Layers (including the Dense layer)\n",
    "- Convolution Layers\n",
    "- Pooling Layers\n",
    "- Recurrent Layers\n",
    "- etc.\n",
    "\n",
    "A simple python code to represent a neural network model using the **Sequential**  model and the Dense layer is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout \n",
    "\n",
    "num_classes =2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=512, activation = 'relu', input_shape = (784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=512, activation = 'relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d70c4",
   "metadata": {},
   "source": [
    "Where,\n",
    "\n",
    "- **Line 1**  imports  **Sequential**  model from Keras models\n",
    "- **Line 2**  imports  **Dense**  layer and  **Activation**  module\n",
    "- **Line 6**  create a new sequential model using  **Sequential**  API\n",
    "- **Line 7**  adds a dense layer (Dense API) with  **relu**  activation (using Activation module) function.\n",
    "- **Line 8**  adds a dropout layer (Dropout API) to handle over-fitting.\n",
    "- **Line 9**  adds another dense layer (Dense API) with  **relu**  activation (using Activation module) function.\n",
    "- **Line 10**  adds another dropout layer (Dropout API) to handle over-fitting.\n",
    "- **Line 11**  adds final dense layer (Dense API) with  **softmax**  activation (using Activation module) function.\n",
    "\n",
    "Keras also provides options to create our own customized layers. Customized layer can be created by sub-classing the  **Keras.Layer**  class and it is similar to sub-classing Keras models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d784851",
   "metadata": {},
   "source": [
    "**Core Modules**\n",
    "\n",
    "Keras also provides a lot of built-in neural network related functions to properly create the Keras model and Keras layers. Some of the function are as follows:\n",
    "\n",
    "\n",
    "\n",
    "- **Initializers**  − Provides a list of initializers function. We can learn it in details in the Keras _layer section. during model creation phase of machine learning.\n",
    "- **Regularizers**  − Provides a list of regularizers functions like L1 regularizer, L2 regularizer, etc.,\n",
    "- **Constraints**  − Provides a list of constraints functions. We can learn it in details in _Keras Layers_ chapter.\n",
    "- **Activations**  − Provides a list of activator functions. We can learn it in details in _Keras Layers_ chapter.\n",
    "- **Losses**  − Provides a list of loss functions like mean\\_squared\\_error, mean\\_absolute\\_error, poisson, etc., \n",
    "- **Metrics**  − Provides a list of metrics functions. We can learn it in details in _Model Training_ chapter.\n",
    "- **Optimizers**  − Provides a list of optimizer functions like adam, sgd, etc.,like adam, sgd, etc.,\n",
    "- **Callback**  − Provides a list of callback function. We can use it during the training process to print the intermediate data as well as to stop the training itself ( **EarlyStopping**  method) based on some condition.\n",
    "- **Utilities**  − Provides lot of utility function useful in deep learning.\n",
    "\n",
    "for a complete list of all modules please check the [Keras API referenceKeras API reference](https://keras.io/api/https://keras.io/api/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfdf91-f066-47df-8649-de2be7eaca79",
   "metadata": {},
   "source": [
    "# Keras - Modules\n",
    "\n",
    "As we learned earlier, Keras provides `Model` and `Layer`s modules with pre-defined classes, functions and variables to build and design deep learning algorithms. \n",
    "\n",
    "Let us first see the list of modules available in Keras as of today:\n",
    "\n",
    "**Callbacks API**\n",
    "- Usage of callbacks via the built-in fit() loop\n",
    "- Using custom callbacks\n",
    "- Available callbacks\n",
    "\n",
    "**Optimizers**\n",
    "- Usage with compile() & fit()\n",
    "- Usage in a custom training loop\n",
    "- Learning rate decay / scheduling\n",
    "- Available optimizers\n",
    "- Core Optimizer API\n",
    "    - apply_gradients method\n",
    "    - variables method\n",
    "\n",
    "**Metrics**\n",
    "- Accuracy metrics\n",
    "- Probabilistic metrics\n",
    "- Regression metrics\n",
    "- Classification metrics based on True/False positives & negatives\n",
    "- Image segmentation metrics\n",
    "- Hinge metrics for \"maximum-margin\" classification\n",
    "- Usage with compile() & fit()\n",
    "- Standalone usage\n",
    "- Creating custom metrics\n",
    "- The add_metric() API\n",
    "\n",
    "**Losses**\n",
    "- Probabilistic losses\n",
    "- Regression losses\n",
    "- Hinge losses for \"maximum-margin\" classification\n",
    "- Usage of losses with compile() & fit()\n",
    "- Standalone usage of losses\n",
    "- Creating custom losses\n",
    "- The add_loss() API\n",
    "\n",
    "\n",
    "**Data loading**\n",
    "- Available dataset loading utilities\n",
    "- Image data loading\n",
    "- Timeseries data loading\n",
    "- Text data loading\n",
    "- Audio data loading\n",
    "\n",
    "\n",
    "**Built-in small datasets**\n",
    "- MNIST digits classification dataset\n",
    "- CIFAR10 small images classification dataset\n",
    "- CIFAR100 small images classification dataset\n",
    "- IMDB movie review sentiment classification dataset\n",
    "- Reuters newswire classification dataset\n",
    "- Fashion MNIST dataset, an alternative to MNIST\n",
    "- Boston Housing price regression dataset\n",
    "\n",
    "\n",
    "**Utilities**\n",
    "- Model plotting utilities\n",
    "- Serialization utilities\n",
    "- Python & NumPy utilities\n",
    "- Backend utilities\n",
    "\n",
    "**KerasTuner API**\n",
    "- HyperParameters\n",
    "- Tuners\n",
    "- Oracles\n",
    "- HyperModels\n",
    "\n",
    "\n",
    "**KerasCV API**\n",
    "- Layers\n",
    "- Metrics\n",
    "- Models\n",
    "- Bounding box formats and utilities\n",
    "\n",
    "\n",
    "**KerasNLP**\n",
    "- Models\n",
    "- Tokenizers\n",
    "- Preprocessing Layers\n",
    "- Modeling Layers\n",
    "- Metrics\n",
    "- Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ab8d9-0f81-4c89-8b7b-fdc135dccea1",
   "metadata": {},
   "source": [
    "Let us see the  **utils**  model to learn useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c2cc6",
   "metadata": {},
   "source": [
    "# `utils` module\n",
    "\n",
    "**utils** provides useful utilities function for deep learning. Some of the methods provided by the **utils** module is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f43f8f",
   "metadata": {},
   "source": [
    "## to_categorical\n",
    "\n",
    "It is used to convert class vector (integers) to binary class matrix. E.g. for use with categorical_crossentropy.E.g. for use with categorical_crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f075d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "normalize([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac7bce",
   "metadata": {},
   "source": [
    "## plot_model\n",
    "\n",
    "It is used to create the model representation in dot format and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728b81e-bd88-4543-9dd5-4844f684ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model,to_file = 'image.png')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=512, activation = 'relu', input_shape = (784,)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=512, activation = 'relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "\n",
    "dot_img_file = '/tmp/model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c30e4de-ae8d-4e34-a8b4-a0b44a34c1ee",
   "metadata": {},
   "source": [
    "This **plot\\_model** will generate an image to understand the performance of model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f6688-5499-41e0-9321-26dd40cea61c",
   "metadata": {},
   "source": [
    "## set_random_seed function\n",
    "\n",
    "\n",
    "Sets all random seeds for the program (Python, NumPy, and TensorFlow).\n",
    "\n",
    "You can use this utility to make almost any Keras program fully deterministic. Some limitations apply in cases where network communications are involved (e.g. parameter server distribution), which creates additional sources of randomness, or when certain non-deterministic cuDNN ops are involved.\n",
    "\n",
    "Calling this utility is equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e9acc-9ea5-4a42-bf4e-0f2aa44de748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed=12345\n",
    "random.seed(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3492c0-94ed-426d-a306-f33518f505b6",
   "metadata": {},
   "source": [
    "## split_dataset function\n",
    "\n",
    "Split a dataset into a left half and a right half (e.g. train / test).\n",
    "\n",
    "Arguments\n",
    "\n",
    "* dataset: A tf.data.Dataset object, or a list/tuple of arrays with the same length.\n",
    "* left_size: If float (in the range [0, 1]), it signifies the fraction of the data to pack in the left dataset. If integer, it signifies the number of samples to pack in the left dataset. If None, it defaults to the complement to right_size.\n",
    "* right_size: If float (in the range [0, 1]), it signifies the fraction of the data to pack in the right dataset. If integer, it signifies the number of samples to pack in the right dataset. If None, it defaults to the complement to left_size.\n",
    "* shuffle: Boolean, whether to shuffle the data before splitting it.\n",
    "* seed: A random seed for shuffling.\n",
    "Returns\n",
    "\n",
    "A tuple of two tf.data.Dataset objects: the left and right splits.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db4769-907d-4c43-90c5-6a7398aee45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random(size=(1000, 4))\n",
    "\n",
    "left_ds, right_ds = tf.keras.utils.split_dataset(data, left_size=0.8)\n",
    "int(left_ds.cardinality())\n",
    "\n",
    "int(right_ds.cardinality())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60104c1-f060-4861-9214-b8383d9282c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Layers\n",
    "\n",
    "As learned earlier, Keras layers are the primary building block of Keras models. Each layer receives input information, do some computation and finally output the transformed information. The output of one layer will flow into the next layer as its input. Let us learn complete details about layers in this tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a73ae",
   "metadata": {},
   "source": [
    "| **No** | **Examples of Layers & their Description** |\n",
    "| --- | --- |\n",
    "| 1 | [Dense Layer](https://www.tutorialspoint.com/keras/keras_dense_layer.htm) **Dense layer**  is the regular deeply connected neural network layer. |\n",
    "| 2 | [Dropout Layers](https://www.tutorialspoint.com/keras/keras_dropout_layers.htm)_ **Dropout** _ is one of the important concept in the machine learning. |\n",
    "| 3 | [Flatten Layers](https://www.tutorialspoint.com/keras/keras_flatten_layers.htm) **Flatten**  is used to flatten the input. |\n",
    "| 4 | [Reshape Layers](https://www.tutorialspoint.com/keras/keras_reshape_layers.htm)_ **Reshape** _ is used to change the shape of the input. |\n",
    "| 5 | [Permute Layers](https://www.tutorialspoint.com/keras/keras_permute_layers.htm) **Permute**  is also used to change the shape of the input using pattern. |\n",
    "| 6 | [RepeatVector Layers](https://www.tutorialspoint.com/keras/keras_repeatvector_layers.htm)_ **RepeatVector** _ is used to repeat the input for set number, n of times. |\n",
    "| 7 | [Lambda Layers](https://www.tutorialspoint.com/keras/keras_lambda_layers.htm)_ **Lambda** _ is used to transform the input data using an expression or function. |\n",
    "| 8 | [Convolution Layers](https://www.tutorialspoint.com/keras/keras_convolution_layers.htm)Keras contains a lot of layers for creating Convolution based ANN, popularly called as _Convolution Neural Network (CNN)_. |\n",
    "| 9 | [Pooling Layer](https://www.tutorialspoint.com/keras/keras_pooling_layer.htm)It is used to perform max pooling operations on temporal data. |\n",
    "| 10 | [Locally connected layer](https://www.tutorialspoint.com/keras/keras_locally_connected_layer.htm)Locally connected layers are similar to Conv1D layer but the difference is Conv1D layer weights are shared but here weights are unshared. |\n",
    "| 11 | [Merge Layer](https://www.tutorialspoint.com/keras/keras_merge_layer.htm)It is used to merge a list of inputs. |\n",
    "| 12 | [Embedding Layer](https://www.tutorialspoint.com/keras/keras_embedding_layer.htm)It performs embedding operations in input layer. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c934d-c4c4-4115-8d20-c37793414953",
   "metadata": {},
   "source": [
    "## The `Layer` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3d7ba-2105-4f74-a968-2da8da9e08b3",
   "metadata": {},
   "source": [
    "Layers are the basic building blocks of neural networks in Keras. A layer consists of a tensor-in tensor-out computation function (the layer's call method) and some state, held in TensorFlow variables (the layer's weights). \n",
    "\n",
    "the Layer class has the following format:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d6563-8f00-4ee2-8a85-dfd1cedbca8b",
   "metadata": {},
   "source": [
    "```Python\n",
    "tf.keras.layers.Layer(\n",
    "    trainable=True, name=None, dtype=None, dynamic=False, **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e89c277-cf60-4d26-ab52-362fa2c2eaa5",
   "metadata": {},
   "source": [
    "This is the class from which all layers inherit.\n",
    "\n",
    "A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors.\n",
    "\n",
    "\n",
    "Users will just instantiate a layer and then treat it as a callable like a function.\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "- trainable: Boolean, whether the layer's variables should be trainable.\n",
    "- name: String name of the layer.\n",
    "- dtype: The dtype of the layer's computations and weights. Can also be a tf.keras.mixed_precision.Policy, which allows the computation and weight dtype to differ. Default of None means to use tf.keras.mixed_precision.global_policy(), which is a float32 policy unless set to different value.\n",
    "- dynamic: Set this to True if your layer should only be run eagerly, and should not be used to generate a static computation graph. This would be the case for a Tree-RNN or a recursive network, for example, or generally for any layer that manipulates tensors using Python control flow. If False, we assume that the layer can safely be used to generate a static computation graph.\n",
    "\n",
    "\n",
    "**Attributes**\n",
    "\n",
    "- name: The name of the layer (string).\n",
    "- dtype: The dtype of the layer's weights.\n",
    "- variable_dtype: Alias of dtype.\n",
    "- compute_dtype: The dtype of the layer's computations. Layers automatically cast inputs to this dtype which causes the computations and output to also be in this dtype. When mixed precision is used with a tf.keras.mixed_precision.Policy, this will be different than variable_dtype.\n",
    "- dtype_policy: The layer's dtype policy. See the tf.keras.mixed_precision.Policy documentation for details.\n",
    "- trainable_weights: List of variables to be included in backprop.\n",
    "- non_trainable_weights: List of variables that should not be included in backprop.\n",
    "- weights: The concatenation of the lists trainable_weights and non_trainable_weights (in this order).\n",
    "- trainable: Whether the layer should be trained (boolean), i.e. whether its potentially-trainable weights should be returned as part of layer.trainable_weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852c40e-f69b-44a6-8d79-4f9838e01cbc",
   "metadata": {},
   "source": [
    "In this example, we see the a customized implementation of a fully connected layer with the linear activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf6f81-9fe1-4cb7-a4bb-e05df5bdb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(Layer):\n",
    "\n",
    "  def __init__(self, units=6):\n",
    "      super(SimpleDense, self).__init__()\n",
    "      self.units = units\n",
    "\n",
    "  def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "    w_init = tf.random_normal_initializer()\n",
    "    self.w = tf.Variable(\n",
    "        initial_value=w_init(shape=(input_shape[-1], self.units),\n",
    "                             dtype='float32'),\n",
    "        trainable=True)\n",
    "    b_init = tf.zeros_initializer()\n",
    "    self.b = tf.Variable(\n",
    "        initial_value=b_init(shape=(self.units,), dtype='float32'),\n",
    "        trainable=True)\n",
    "\n",
    "  def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "      return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2fd9f-ab76-46d8-b12e-b29bd4ed6cfb",
   "metadata": {},
   "source": [
    "Let's test this layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fad7a-0432-413f-904d-67f55ec5475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the layer.\n",
    "linear_layer = SimpleDense(6)\n",
    "\n",
    "# This will also call `build(input_shape)` and create the weights.\n",
    "y = linear_layer(tf.ones((2, 2)))\n",
    "assert len(linear_layer.weights) == 2\n",
    "\n",
    "# These weights are trainable, so they're listed in `trainable_weights`:\n",
    "assert len(linear_layer.trainable_weights) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca71ba-b860-49c8-b638-1cb1779f2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sum = SimpleDense(6)\n",
    "\n",
    "x = tf.ones((2, 2))\n",
    "\n",
    "y = my_sum(x)\n",
    "print(y.numpy()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2265a53-f9fc-433b-99d0-7f6aaa6421c2",
   "metadata": {},
   "source": [
    "A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. \n",
    "\n",
    "It involves computation, defined in the call() method, and a state (weight variables). State can be created in various places, at the convenience of the subclass implementer:\n",
    "\n",
    "- in __init__();\n",
    "- in the optional build() method, which is invoked by the first __call__() to the layer, and supplies the shape(s) of the input(s), which may not have been known at initialization time;\n",
    "- in the first invocation of call(), with some caveats discussed below.\n",
    "\n",
    "Layers are recursively composable: If you assign a Layer instance as an attribute of another Layer, the outer layer will start tracking the weights created by the inner layer. Nested layers should be instantiated in the __init__() method.\n",
    "\n",
    "Users will just instantiate a layer and then treat it as a callable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437d2b5-6389-4f0c-84d9-eb59cc2f3e80",
   "metadata": {},
   "source": [
    "This implementation can be obtained with the Dense layer, which is a Keras Core layer by instanciating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f9f25-6fac-40d6-b031-37c9ca96d65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "MySimpleDense = Dense(units=6, activation='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b99a97-9767-49e8-b132-851f7990721a",
   "metadata": {},
   "source": [
    "Let's review couple of core layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b79a1-2a61-4866-a527-6bc4c55ab687",
   "metadata": {},
   "source": [
    "## Core layers\n",
    "\n",
    "Layers are recursively composable: If you assign a Layer instance as an attribute of another Layer, the outer layer will start tracking the weights created by the inner layer.\n",
    "\n",
    "There core layers can be nested.\n",
    "- Input object\n",
    "- Dense layer\n",
    "- Activation layer\n",
    "- Embedding layer\n",
    "- Masking layer\n",
    "- Lambda layer\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2a798-f994-4500-a428-ed96671e5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(32,)))\n",
    "model.add(Dense(units=512, \n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9125477-95d6-4de8-8d6f-580c386a9a1e",
   "metadata": {},
   "source": [
    "this model can be rewritten as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21940f52-8224-499f-8822-f9c192d555ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, \n",
    "                activation = 'softmax', \n",
    "                input_shape = (32,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4671d-428a-4239-9e3e-4eba3559e5a5",
   "metadata": {},
   "source": [
    "or using the function API (to discuss later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e03c87-2cac-4167-8b71-672870f33210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras import Model\n",
    "\n",
    "# this is a logistic regression in Keras\n",
    "x = Input(shape=(32,))\n",
    "y = Dense(16, activation='softmax')(x)\n",
    "\n",
    "model = Model(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbcdad-cce7-4646-80e0-aca1fd5f0a67",
   "metadata": {},
   "source": [
    "## Defining Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad4160-aefd-4eaa-81ef-b35e0c6f187d",
   "metadata": {
    "tags": []
   },
   "source": [
    "A Keras layer requires **shape of the input** (```input_shape```) to understand the structure of the input data,  **initializer** to set the weight for each input and finally activators to transform the output to make it non-linear.\n",
    "\n",
    "In between, constraints restricts and specify the range in which the weight of input data to be generated and regularizer will try to optimize the layer (and the model) by dynamically applying the penalties on the weights during optimization process.\n",
    "\n",
    "To summarise, Keras layer requires below minimum details to create a complete layer.\n",
    "\n",
    "- Shape of the input data\n",
    "- Number of neurons / units in the layer\n",
    "- Initializers\n",
    "- Regularizers\n",
    "- Constraints\n",
    "- Activations\n",
    "\n",
    "Let us understand the basic concept in the next chapter. Before understanding the basic concept, let us create a simple Keras layer using Sequential model API to get the idea of how Keras model and layer works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ff4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(units=32, \n",
    "                input_shape=(16,), \n",
    "                kernel_initializer ='he_uniform',\n",
    "                kernel_regularizer =None, \n",
    "                kernel_constraint ='MaxNorm', activation ='relu'))\n",
    "\n",
    "model.add(Dense(16, activation ='relu'))\n",
    "model.add(Dense(8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b7127-648a-4b63-8c0b-a1232943fa0c",
   "metadata": {},
   "source": [
    "where,\n",
    "\n",
    "- **Line 1-6**  imports the necessary modules.\n",
    "- **Line 8**  creates a new model using Sequential API.\n",
    "- **Line 10**  creates a new _ **Dense** _ layer and add it into the model. _ **Dense** _ is an entry level layer provided by Keras, which accepts the number of neurons or units (32) as its required parameter. If the layer is first layer, then we need to provide **Input Shape, (16,)** as well. Otherwise, the output of the previous layer will be used as input of the next layer.\n",
    "\n",
    "All other parameters are optional.\n",
    "  - **units**, is the first parameter represents the number of units (neurons).\n",
    "  - **input\\_shape** represent the shape of input data.\n",
    "  - **kernel\\_initializer** represent initializer to be used. **he\\_uniform** _ function is set as value.\n",
    "  - **kernel\\_regularizer** represent  **regularizer**  to be used. None is set as value.\n",
    "  - **kernel\\_constraint** represent constraint to be used. **MaxNorm** function is set as value.\n",
    "  - **activation** represent activation to be used. relu function is set as value.\n",
    "  \n",
    "- **Line 15**  creates second _ **Dense** _ layer with 16 units and set _ **relu** _ as the activation function.\n",
    "- **Line 16**  creates final Dense layer with 8 units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379615e-c04c-4eb3-a17d-1034b36e0593",
   "metadata": {},
   "source": [
    "Let us understand the basic concept of layer as well as how Keras supports each concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfeb03a-e5c0-4299-b74a-7ade80048fbd",
   "metadata": {},
   "source": [
    "## Input shape\n",
    "\n",
    "In machine learning, all type of input data like text, images or videos will be first converted into array of numbers and then feed into the algorithm. Input numbers may be single dimensional array, two dimensional array (matrix) or multi-dimensional array. We can specify the dimensional information using  **shape** , a tuple of integers. For example, **(4,2)** represent matrix with four rows and two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shape =(4,2)\n",
    "input = np.zeros(shape)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7bba08",
   "metadata": {},
   "source": [
    "Similarly, **(3,4,2)** three dimensional matrix having three collections of 4x2 matrix (two rows and four columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9876a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shape =(3,4,2)\n",
    "input = np.zeros(shape)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c806b2a",
   "metadata": {},
   "source": [
    "To create the first layer of the model (or input layer of the model), shape of the input data should be specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ff02a-93ca-408d-935b-9abdeb1c1290",
   "metadata": {},
   "source": [
    "## Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b33133-6877-4ce0-bd1a-6b7d2cfbc267",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Layer weight initializers\n",
    "\n",
    "Initializers define the way to set the initial random weights of Keras layers. The keyword arguments used for passing initializers to layers depends on the layer.\n",
    "\n",
    "The **Initializers** Layer provides different functions to set these initial weight. Usually, it is simply `kernel_initializer` and `bias_initializer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c6792-6f5f-4b9b-a9e5-8b6e1ea162bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "layer = layers.Dense(\n",
    "    units=64,\n",
    "    kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Zeros()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b385d8a-24ca-452d-9c9e-db9fc1863a1d",
   "metadata": {},
   "source": [
    "All built-in initializers can also be passed via their string identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0fe74a-590d-4752-923a-7b5cdb75cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Dense(\n",
    "    units=64,\n",
    "    kernel_initializer='random_normal',\n",
    "    bias_initializer='zeros'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457dce4-7af6-4835-bc3d-d48bd65f34bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following built-in initializers are available as part of the `tf.keras.initializers` module:\n",
    "\n",
    "### Zeros\n",
    "\n",
    "Generates  **0**  for all weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ade04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.Zeros()\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258492e",
   "metadata": {},
   "source": [
    "Where, _ **kernel\\_initializer** _ represent the initializer for kernel of the model.\n",
    "\n",
    "### Ones\n",
    "\n",
    "Generates  **1**  for layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.Ones()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "\n",
    "kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f3505",
   "metadata": {},
   "source": [
    "### Constant\n",
    "\n",
    "Generates a constant value (say,  **5** ) specified by the user for all input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.Constant(value=0) \n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,), \n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e0156",
   "metadata": {},
   "source": [
    "where,  **value**  represent the constant value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6611c5",
   "metadata": {},
   "source": [
    "### RandomNormal\n",
    "\n",
    "Generates value using normal distribution of layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46760c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.RandomNormal(mean=0.0, \n",
    "                                    stddev =0.05, \n",
    "                                    seed =None)\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cebe93",
   "metadata": {},
   "source": [
    "where,\n",
    "\n",
    "- _ **mean** _ represent the mean of the random values to generate\n",
    "- _ **stddev** _ represent the standard deviation of the random values to generate\n",
    "- _ **seed** _ represent the values to generate random number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2d1b6",
   "metadata": {},
   "source": [
    "### RandomUniform\n",
    "\n",
    "Generates value using uniform distribution of layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.RandomUniform(minval =-0.05, \n",
    "                                     maxval =0.05, \n",
    "                                     seed =None)\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "\n",
    "kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78caea6f",
   "metadata": {},
   "source": [
    "where,\n",
    "\n",
    "- _ **minval** _ represent the lower bound of the random values to generate\n",
    "- _ **maxval** _ represent the upper bound of the random values to generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474032a",
   "metadata": {},
   "source": [
    "### TruncatedNormal\n",
    "\n",
    "Generates value using truncated normal distribution of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.TruncatedNormal(mean =0.0, \n",
    "                                       stddev =0.05, \n",
    "                                       seed =None)\n",
    "\n",
    "model.add(Dense(512, \n",
    "                activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e24295",
   "metadata": {},
   "source": [
    "### VarianceScaling\n",
    "\n",
    "Generates value based on the input shape and output shape of the layer along with the specified scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c678043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.VarianceScaling(scale =1.0, \n",
    "                                       mode ='fan_in', \n",
    "                                       distribution ='normal', \n",
    "                                       seed =None)\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2443a",
   "metadata": {},
   "source": [
    "where,\n",
    "\n",
    "- **scale**  represent the scaling factor\n",
    "- **mode**  represent any one of  **fan\\_in, fan\\_out**  and  **fan\\_avg**  values\n",
    "- **distribution**  represent either of  **normal**  or  **uniform**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a47cfb",
   "metadata": {},
   "source": [
    "The VarianceScaling finds the _ **stddev** _ value for normal distribution using below formula and then find the weights using normal distribution,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543799c6-9306-44bd-bf04-a04f182282fc",
   "metadata": {},
   "source": [
    "```Python \n",
    "stddev = sqrt(scale/n)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c8c1f",
   "metadata": {},
   "source": [
    "where  **n**  represent,\n",
    "\n",
    "- number of input units for mode = fan\\_in\n",
    "- number of out units for mode = fan\\_out\n",
    "- average number of input and output units for mode = fan\\_avg\n",
    "\n",
    "Similarly, it finds the _limit_ for uniform distribution using below formula and then find the weights using uniform distribution,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ade49-070d-4ec5-8d36-2ebb30ccfc90",
   "metadata": {},
   "source": [
    "```Python \n",
    "limit = sqrt(3 * scale / n)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707707c1",
   "metadata": {},
   "source": [
    "### lecun_normal\n",
    "\n",
    "Generates value using lecun normal distribution of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.RandomUniform(minval =-0.05, \n",
    "                                     maxval =0.05, \n",
    "                                     seed =None)\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c8757",
   "metadata": {},
   "source": [
    "It finds the _ **stddev** _ using the below formula and then apply normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69ef6f-790d-4383-9ddd-6a9a99d3f241",
   "metadata": {},
   "source": [
    "```Python \n",
    "stddev = sqrt(1 / fan_in)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a8cb5",
   "metadata": {},
   "source": [
    "where, **fan\\_in** _ represent the number of input units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc09e5",
   "metadata": {},
   "source": [
    "### lecun\\_uniform\n",
    "\n",
    "Generates value using lecun uniform distribution of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.lecun_uniform(seed =None)\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1152e4e",
   "metadata": {},
   "source": [
    "It finds the **limit** _ using the below formula and then apply uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06acfd2-8a73-41de-a6fd-89a8acf746db",
   "metadata": {},
   "source": [
    "```Python \n",
    "limit = sqrt(3 / fan_in)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6f264",
   "metadata": {},
   "source": [
    "where,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c2f3d",
   "metadata": {},
   "source": [
    "- **fan\\_in** _ represents the number of input units\n",
    "- **fan\\_out** _ represents the number of output units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865abf1",
   "metadata": {},
   "source": [
    "## Layer weight constraints\n",
    "\n",
    "\n",
    "Classes from the `tf.keras.constraints` module allow setting constraints (eg. non-negativity) on model parameters during training. They are per-variable projection functions applied to the target variable after each gradient update (when using fit()).\n",
    "\n",
    "The exact API will depend on the layer, but the layers Dense, Conv1D, Conv2D and Conv3D have a unified API.\n",
    "\n",
    "These layers expose two keyword arguments:\n",
    "\n",
    "kernel_constraint for the main weights matrix\n",
    "bias_constraint for the bias.Classes from the tf.keras.constraints module allow setting constraints (eg. non-negativity) on model parameters during training. They are per-variable projection functions applied to the target variable after each gradient update (when using fit()).\n",
    "\n",
    "The exact API will depend on the layer, but the layers Dense, Conv1D, Conv2D and Conv3D have a unified API.\n",
    "\n",
    "These layers expose two keyword arguments:\n",
    "- `kernel_constraint` for the main weights matrix\n",
    "- `bias_constraint` for the bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef1e18-4d2d-403a-a104-a330aedcf34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "model.add(Dense(64, kernel_constraint=max_norm(2.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c86c8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NonNeg\n",
    "\n",
    "Constrains weights to be non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_init = initializers.Identity(gain =1.0) \n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_initializer = my_init)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb598139",
   "metadata": {},
   "source": [
    "where, _ **kernel\\_constraint** _ represent the constraint to be used in the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edee44",
   "metadata": {},
   "source": [
    "### UnitNorm\n",
    "\n",
    "Constrains weights to be unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_constrain = constraints.UnitNorm(axis =0)\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_constraint = my_constrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b112e29",
   "metadata": {},
   "source": [
    "### MaxNorm\n",
    "\n",
    "Constrains weight to norm less than or equals to the given value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_constrain = constraints.MaxNorm(max_value =2, axis =0)\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_constraint = my_constrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99165ae5",
   "metadata": {},
   "source": [
    "where,\n",
    "\n",
    "- _ **max\\_value** _ represent the upper bound\n",
    "- _axis_ represent the dimension in which the constraint to be applied. e.g. in Shape (2,3,4) axis 0 denotes first dimension, 1 denotes second dimension and 2 denotes third dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c20b1f",
   "metadata": {},
   "source": [
    "### MinMaxNorm\n",
    "\n",
    "Constrains weights to be norm between specified minimum and maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4d2c5",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_constrain = constraints.MinMaxNorm(min_value =0.0, max_value =1.0, rate =1.0, axis =0)\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_constraint = my_constrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9953b9",
   "metadata": {},
   "source": [
    "where, _ **rate** _ represent the rate at which the weight constrain is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b7eb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Layer weight regularizers\n",
    "\n",
    "Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes.\n",
    "\n",
    "Regularization penalties are applied on a per-layer basis. The exact API will depend on the layer, but many layers (e.g. Dense, Conv1D, Conv2D and Conv3D) have a unified API.\n",
    "\n",
    "These layers expose 3 keyword arguments:\n",
    "\n",
    "- kernel_regularizer: Regularizer to apply a penalty on the layer's kernel\n",
    "- bias_regularizer: Regularizer to apply a penalty on the layer's bias\n",
    "- activity_regularizer: Regularizer to apply a penalty on the layer's outputRegularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes.\n",
    "\n",
    "Regularization penalties are applied on a per-layer basis. The exact API will depend on the layer, but many layers (e.g. Dense, Conv1D, Conv2D and Conv3D) have a unified API.\n",
    "\n",
    "These layers expose 3 keyword arguments:\n",
    "\n",
    "- `kernel_regularizer`: Regularizer to apply a penalty on the layer's kernel\n",
    "- `bias_regularizer`: Regularizer to apply a penalty on the layer's bias\n",
    "- `activity_regularizer`: Regularizer to apply a penalty on the layer's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73f8cb",
   "metadata": {},
   "source": [
    "### L1 Regularizer\n",
    "\n",
    "It provides L1 based regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b788853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "# A regularizer that applies a L1 regularization penalty.\n",
    "my_regularizer = regularizers.l1(0.1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 512, activation = 'relu', \n",
    "                input_shape = (784,),\n",
    "                kernel_regularizer = my_regularizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d075f",
   "metadata": {},
   "source": [
    "where, **kernel\\_regularizer** represents the rate at which the weight constrain is applied.\n",
    "\n",
    "The L1 regularization penalty is computed as: `loss = l1 * reduce_sum(abs(x))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7d237-d792-45d7-aaef-67816e9faf8d",
   "metadata": {},
   "source": [
    "L1 may be passed to a layer as a string identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90113ffe-5d79-421e-9581-de74a17e41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(3, kernel_regularizer='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac61747-4676-405b-ae74-358a8b5f7e9d",
   "metadata": {},
   "source": [
    "In this case, the default value used is `l1=0.01`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4b36b",
   "metadata": {},
   "source": [
    "### L2 Regularizer\n",
    "\n",
    "A regularizer that applies a L2 regularization penalty.\n",
    "\n",
    "The L2 regularization penalty is computed as: `loss = l2 * reduce_sum(square(x))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "my_regularizer = regularizers.l2(0.1)\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_regularizer = my_regularizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1078d84-5ba6-439c-9b7a-f1c68a9e5cdb",
   "metadata": {},
   "source": [
    "L2 may be passed to a layer as a string identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e020f-aa27-4186-8e77-fedbdb1da731",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(3, kernel_regularizer='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d9e74-94bd-4eea-a947-37d1a634ed0b",
   "metadata": {},
   "source": [
    "In this case, the default value used is l2=0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e0705",
   "metadata": {},
   "source": [
    "### L1 and L2 Regularizer\n",
    "\n",
    "It provides both L1 and L2 based regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765faf63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Activations\n",
    "\n",
    "In machine learning, activation function is a special function used to find whether a specific neuron is activated or not. Basically, the activation function does a nonlinear transformation of the input data and thus enable the neurons to learn better. Output of a neuron depends on the activation function.\n",
    "\n",
    "As you recall the concept of single perception, the output of a perceptron (neuron) is simply the result of the activation function, which accepts the summation of all input multiplied with its corresponding weight plus overall bias, if any available.\n",
    "\n",
    ">result = Activation(SUMOF(input \\* weight) + bias)\n",
    "\n",
    "So, activation function plays an important role in the successful learning of the model. Keras provides a lot of activation function in the activations module. Let us learn all the activations available in the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "from keras import initializers\n",
    "\n",
    "my_regularizer = regularizers.l2(0.)\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,),\n",
    "                kernel_regularizer = my_regularizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ef37e",
   "metadata": {},
   "source": [
    "### linear\n",
    "\n",
    "Applies Linear function. Does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 512, activation = 'linear', \n",
    "                input_shape = (784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd620e9d",
   "metadata": {},
   "source": [
    "Where, _ **activation** _ refers the activation function of the layer. It can be specified simply by the name of the function and the layer will use corresponding activators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850ef0f",
   "metadata": {},
   "source": [
    "### elu\n",
    "\n",
    "Applies Exponential linear unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88690f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='elu', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a59f0d",
   "metadata": {},
   "source": [
    "### selu\n",
    "\n",
    "Applies Scaled exponential linear unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90173ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(512, activation ='selu', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf79c4",
   "metadata": {},
   "source": [
    "### relu\n",
    "\n",
    "Applies Rectified Linear Unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af922aa9",
   "metadata": {},
   "source": [
    "\n",
    "### softmax\n",
    "\n",
    "Applies Softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(512, activation ='softmax', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1318070",
   "metadata": {},
   "source": [
    "### softplus\n",
    "\n",
    "Applies Softplus function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d80000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "model.add(Dense(512, activation ='softplus', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb7cf5",
   "metadata": {},
   "source": [
    "### softsign\n",
    "\n",
    "Applies Softsign function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='softsign', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da631fe9",
   "metadata": {},
   "source": [
    "### tanh\n",
    "\n",
    "Applies Hyperbolic tangent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='tanh', input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfaa0d7",
   "metadata": {},
   "source": [
    "### sigmoid\n",
    "\n",
    "Applies Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ade2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='sigmoid', input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bc8f7",
   "metadata": {},
   "source": [
    "### hard_sigmoid\n",
    "\n",
    "Applies Hard Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='hard_sigmoid', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bdec9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### exponential\n",
    "\n",
    "Applies exponential function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(units = 512, \n",
    "                activation ='exponential', \n",
    "                input_shape =(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7cb86f-a1ed-4bac-aa63-351775b69617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db235b51",
   "metadata": {},
   "source": [
    "## Customized Layer\n",
    "\n",
    "Keras allows to create our own customized layer. Once a new layer is created, it can be used in any model without any restriction. Let us learn how to create new layer in this chapter.\n",
    "\n",
    "Keras provides a base  **layer**  class, Layer which can sub-classed to create our own customized layer. Let us create a simple layer which will find weight based on normal distribution and then do the basic computation of finding the summation of the product of input and its weight during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a0549",
   "metadata": {},
   "source": [
    "Step 1: Import the necessary module\n",
    "\n",
    "First, let us import the necessary modules −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f4d45",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- **backend**  is used to access the  **dot**  function.\n",
    "- **Layer**  is the base class and we will be sub-classing it to create our layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be7426",
   "metadata": {},
   "source": [
    "Step 2: Define a layer class\n",
    "\n",
    "Let us create a new class,  **MyCustomLayer**  by sub-classing  **Layer class**  −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a252d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomLayer(Layer):\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae618139",
   "metadata": {},
   "source": [
    "Step 3: Initialize the layer class\n",
    "\n",
    "Let us initialize our new class as specified below −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyCustomLayer, self).__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2fe530",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- **Line 2**  sets the output dimension.\n",
    "- **Line 3**  calls the base or super layer's  **init**  function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52fad4",
   "metadata": {},
   "source": [
    "Step 4: Implement build method\n",
    "\n",
    "**build**  is the main method and its only purpose is to build the layer properly. It can do anything related to the inner working of the layer. Once the custom functionality is done, we can call the base class  **build**  function. Our custom  **build**  function is as follows −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45672dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self, input_shape):\n",
    "    self.kernel =self.add_weight(name ='kernel',\n",
    "                                 shape =(input_shape[1],self.output_dim),\n",
    "                                 initializer ='normal', trainable =True)\n",
    "\n",
    "    super(MyCustomLayer,self).build(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5246b",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- **Line 1**  defines the  **build**  method with one argument,  **input\\_shape**. Shape of the input data is referred by input\\_shape.\n",
    "- **Line 2**  creates the weight corresponding to input shape and set it in the kernel. It is our custom functionality of the layer. It creates the weight using 'normal' initializer.\n",
    "- **Line 6**  calls the base class,  **build**  method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8658ab4",
   "metadata": {},
   "source": [
    "Step 5: Implement call method\n",
    "\n",
    "**call**  method does the exact working of the layer during training process.\n",
    "\n",
    "Our custom  **call**  method is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de73bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, input_data):\n",
    "    return K.dot(input_data, self.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d066901",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- **Line 1**  defines the  **call**  method with one argument,  **input\\_data**. input\\_data is the input data for our layer.\n",
    "- **Line 2**  return the dot product of the input data,  **input\\_data**  and our layer's kernel,  **self.kernel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a83fd5",
   "metadata": {},
   "source": [
    "Step 6: Implement compute_output_shape method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_output_shape(self, input_shape): return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac0873",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- **Line 1**  defines  **compute\\_output\\_shape**  method with one argument  **input\\_shape**\n",
    "- **Line 2**  computes the output shape using shape of input data and output dimension set while initializing the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21230617",
   "metadata": {},
   "source": [
    "Implementing the  **build, call**  and  **compute\\_output\\_shape**  completes the creating a customized layer. The final and complete code is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379df1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "from keras.layers import Layer\n",
    "\n",
    "class MyCustomLayer(Layer): \n",
    "    def __init__(self, output_dim, **kwargs): \n",
    "        self.output_dim = output_dim \n",
    "        super(MyCustomLayer, self).__init__(**kwargs) \n",
    "    \n",
    "    def build(self, input_shape): \n",
    "        self.kernel = self.add_weight(name = 'kernel', \n",
    "                        shape = (input_shape[1], self.output_dim),\n",
    "                        initializer = 'normal', trainable = True) \n",
    "        super(MyCustomLayer, self).build(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d1d15",
   "metadata": {},
   "source": [
    "Be sure to call this at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, input_data):return K.dot(input_data,self.kernel)\n",
    "\n",
    "def compute_output_shape(self, input_shape):return(input_shape[0],\n",
    "                                                   self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451de67",
   "metadata": {},
   "source": [
    "Using our customized layer\n",
    "\n",
    "Let us create a simple model using our customized layer as specified below −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(MyCustomLayer(32, input_shape =(16,)))\n",
    "\n",
    "model.add(Dense(8, activation ='softmax')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c85c1",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- Our  **MyCustomLayer**  is added to the model using 32 units and **(16,)** as input shape\n",
    "\n",
    "Running the application will print the model summary as below −"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99aad36-6f32-45b8-b3b2-f9df7be0bd8e",
   "metadata": {},
   "source": [
    "# Model API\n",
    "\n",
    "As learned earlier, Keras model API represents the actual neural network model. \n",
    "There are three ways to create Keras models:\n",
    "\n",
    "- **The Sequential model**, which is very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers (as the name gives away).\n",
    "- **The Functional API**, which is an easy-to-use, fully-featured API that supports arbitrary model architectures. For most people and most use cases, this is what you should be using. This is the Keras \"industry strength\" model.\n",
    "- **Model subclassing**, where you implement everything from scratch on your own. Use this if you have complex, out-of-the-box research use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1037911-07a4-4b4e-a7ee-a8ba285f80b9",
   "metadata": {},
   "source": [
    "## Models API overview\n",
    "\n",
    "**The Model class**\n",
    "- Model class\n",
    "- summary method\n",
    "- get_layer method\n",
    "\n",
    "\n",
    "**The Sequential class**\n",
    "- Sequential class\n",
    "- add method\n",
    "- pop method\n",
    "\n",
    "**Model training APIs**\n",
    "- compile method\n",
    "- fit method\n",
    "- evaluate method\n",
    "- predict method\n",
    "- train_on_batch method\n",
    "- test_on_batch method\n",
    "- predict_on_batch method\n",
    "- run_eagerly property\n",
    "\n",
    "**Model saving & serialization APIs**\n",
    "- save method\n",
    "- save_model function\n",
    "- load_model function\n",
    "- get_weights method\n",
    "- set_weights method\n",
    "- save_weights method\n",
    "- load_weights method\n",
    "- get_config method\n",
    "- from_config method\n",
    "- model_from_config function\n",
    "- to_json method\n",
    "- model_from_json function\n",
    "- clone_model function\n",
    "\n",
    "[source](https://keras.io/api/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31227607-3164-4579-99ed-1753e0d7f0ad",
   "metadata": {},
   "source": [
    " Let us learn now to create model using both **Sequential** and **Functional API** in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301b8ed-c32d-40f6-8bf3-aa46eea7955b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sequential\n",
    "\n",
    "The core idea of _ **Sequential API** _ is simply arranging the Keras layers in a sequential order and so, it is called _Sequential API_.\n",
    "\n",
    "Most of the ANN also has layers in sequential order and the data flows from one layer to another layer in the given order until the data finally reaches the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43da2d6-a858-48f6-8ef7-63a5cc2a848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Sequential class\n",
    "tf.keras.Sequential(layers=None, name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ed9b4-60fc-4ff7-88f3-0f251e5c0375",
   "metadata": {},
   "source": [
    "A ANN model can be created by simply calling **Sequential()** API as specified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e965e",
   "metadata": {},
   "source": [
    "### Add layers\n",
    "\n",
    "To add a layer, simply create a layer using Keras layer API and then pass the layer through add() function as specified below −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e90816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "input_layer =Dense(units=32, input_shape=(8,)) \n",
    "\n",
    "model.add(input_layer)\n",
    "\n",
    "# or model.add(Dense(units=32, input_shape=(8,)))\n",
    "\n",
    "\n",
    "hidden_layer =Dense(64, activation='relu'); \n",
    "model.add(hidden_layer)\n",
    "\n",
    "output_layer =Dense(8)\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669ed3a-f1dd-45fa-bf40-bd2aceb0dd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf106f1",
   "metadata": {},
   "source": [
    "Here, we have created one input layer, one hidden layer and one output layer.\n",
    "\n",
    "### Access the model\n",
    "\n",
    "Keras provides few methods to get the model information like layers, input data and output data. They are as follows:\n",
    "\n",
    "- **model.layers** − Returns all the layers of the model as list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c52911",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00022964",
   "metadata": {},
   "source": [
    "- _ **model.inputs** _ − Returns all the input tensors of the model as list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f948e-29df-448d-ab81-cbc728c729d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model.inputs\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.outputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887b98a",
   "metadata": {},
   "source": [
    "- **model.get\\_weights** − Returns all the weights as NumPy arrays.\n",
    "- _**model.set\\_weights(weight\\_numpy\\_array)**_ − Set the weights of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac00f2",
   "metadata": {},
   "source": [
    "### Serialize the model\n",
    "\n",
    "Keras provides methods to serialize the model into object as well as json and load it again later. They are as follows −\n",
    "\n",
    "- _**get\\_config()**_ − IReturns the model as an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1feeab",
   "metadata": {},
   "source": [
    "- _**from\\_config()**_ − It accept the model configuration object as argument and create the model accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a75442",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe87872",
   "metadata": {},
   "source": [
    "- _**to\\_json()**_ − Returns the model as an json object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ffa83",
   "metadata": {},
   "source": [
    "- _**model\\_from\\_json()**_ − Accepts json representation of the model and create a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "new_model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcedba",
   "metadata": {},
   "source": [
    "### Summarise the model\n",
    "\n",
    "Understanding the model is very important phase to properly use it for training and prediction purposes. Keras provides a simple method, summary to get the full information about the model and its layers.\n",
    "\n",
    "A summary of the model created in the previous section is as follows −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dfbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a723347",
   "metadata": {},
   "source": [
    "### Train and Predict the model\n",
    "\n",
    "Model provides function for training, evaluation and prediction process. They are as follows −\n",
    "\n",
    "- **compile**  − Configure the learning process of the model\n",
    "- **fit**  − Train the model using the training data\n",
    "- **evaluate**  − Evaluate the model using the test data\n",
    "- **predict**  − Predict the results for new input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788e7ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functional API\n",
    "\n",
    "Sequential API is used to create models layer-by-layer. Functional API is an alternative approach of creating more complex models. Functional model, you can define multiple input or output that share layers. First, we create an instance for model and connecting to the layers to access input and output to the model. This section explains about functional model in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5952e",
   "metadata": {},
   "source": [
    "Create a model\n",
    "\n",
    "Import an input layer using the below module −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5968b90",
   "metadata": {},
   "source": [
    "Now, create an input layer specifying input dimension shape for the model using the below code −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960efb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Input(shape=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8907debb",
   "metadata": {},
   "source": [
    "Define layer for the input using the below module −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d10e0",
   "metadata": {},
   "source": [
    "Add Dense layer for the input using the below line of code −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer =Dense(2)(data)\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddfcace",
   "metadata": {},
   "source": [
    "Define model using the below module −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf2d23",
   "metadata": {},
   "source": [
    "Create a model in functional way by specifying both input and output layer −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab35bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = data, outputs = layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fb663",
   "metadata": {},
   "source": [
    "The complete code to create a simple model is shown below −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "data =Input(shape=(2,3))\n",
    "\n",
    "layer =Dense(2)(data) \n",
    "\n",
    "model =Model(inputs=data,outputs=layer) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e03beb-50b7-449a-8593-65e1aef80dba",
   "metadata": {},
   "source": [
    "We will cover the **Keras Functional API** later with more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6155ff",
   "metadata": {},
   "source": [
    "## Model Compilation\n",
    "\n",
    "Previously, we studied the basics of how to create model using Sequential and Functional API. This chapter explains about how to compile the model. The compilation is the final step in creating a model. Once the compilation is done, we can move on to training phase.\n",
    "\n",
    "Let us learn few concepts required to better understand the compilation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154b941",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "In machine learning,  **Loss**  function is used to find error or deviation in the learning process. Keras requires loss function during model compilation process.\n",
    "\n",
    "Keras provides quite a few loss function in the  **losses**  module and they are as follows −\n",
    "\n",
    "- mean\\_squared\\_error\n",
    "- mean\\_absolute\\_error\n",
    "- mean\\_absolute\\_percentage\\_error\n",
    "- mean\\_squared\\_logarithmic\\_error\n",
    "- squared\\_hinge\n",
    "- hinge\n",
    "- categorical\\_hinge\n",
    "- logcosh\n",
    "- huber\\_loss\n",
    "- categorical\\_crossentropy\n",
    "- sparse\\_categorical\\_crossentropy\n",
    "- binary\\_crossentropy\n",
    "- kullback\\_leibler\\_divergence\n",
    "- poisson\n",
    "- cosine\\_proximity\n",
    "- is\\_categorical\\_crossentropy\n",
    "\n",
    "All above loss function accepts two arguments −\n",
    "\n",
    "- **y\\_true**  − true labels as tensors\n",
    "- **y\\_pred**  − prediction with same shape as  **y\\_true**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acd023",
   "metadata": {},
   "source": [
    "Import the losses module before using loss function as specified below −"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551eb9d",
   "metadata": {},
   "source": [
    "from keras import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56fc639-964e-40da-912c-f0f2f4b5d192",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "In machine learning,  **Optimization**  is an important process which optimize the input weights by comparing the prediction and the loss function. Keras provides quite a few optimizer as a module, _optimizers_ and they are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2c140",
   "metadata": {},
   "source": [
    "Import the optimizers module before using optimizers as specified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df642c84-8c87-47c9-a8b1-8a6b6446f078",
   "metadata": {},
   "source": [
    "**SGD**  − Stochastic gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.0, nesterov = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c49dbf",
   "metadata": {},
   "source": [
    "**RMSprop**  − RMSProp optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.RMSprop(learning_rate = 0.001, rho = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a074a",
   "metadata": {},
   "source": [
    "**Adagrad**  − Adagrad optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adagrad(learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1063d6",
   "metadata": {},
   "source": [
    "**Adadelta**  − Adadelta optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adadelta(learning_rate = 1.0, rho = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f156ead",
   "metadata": {},
   "source": [
    "**Adam**  − Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adam(learning_rate =0.001, beta_1 =0.9, beta_2 =0.999, amsgrad =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c9193",
   "metadata": {},
   "source": [
    "**Adamax**  − Adamax optimizer from Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adamax(learning_rate = 0.002, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e7c75",
   "metadata": {},
   "source": [
    "**Nadam**  − Nesterov Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1292a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Nadam(learning_rate = 0.002, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa5ba4-757b-4836-8532-84e9bb5336c1",
   "metadata": {},
   "source": [
    "We will cover the Optimizers later with more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3845d2a",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In machine learning,  **Metrics**  is used to evaluate the performance of your model. It is similar to loss function, but not used in training process. Keras provides quite a few metrics as a module,  **metrics**  and they are as follows\n",
    "\n",
    "- accuracy\n",
    "- binary\\_accuracy\n",
    "- categorical\\_accuracy\n",
    "- sparse\\_categorical\\_accuracy\n",
    "- top\\_k\\_categorical\\_accuracy\n",
    "- sparse\\_top\\_k\\_categorical\\_accuracy\n",
    "- cosine\\_proximity\n",
    "- clone\\_metric\n",
    "\n",
    "Similar to loss function, metrics also accepts below two arguments −\n",
    "\n",
    "- **y\\_true**  − true labels as tensors\n",
    "- **y\\_pred**  − prediction with same shape as  **y\\_true**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35734d63",
   "metadata": {},
   "source": [
    "Import the metrics module before using metrics as specified below −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730c1a2",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "\n",
    "Keras model provides a method, **compile()** to compile the model. The argument and default value of the **compile()** method is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ce148-d13a-45ea-b997-5ede1152e735",
   "metadata": {},
   "source": [
    "```Python\n",
    "Model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=None,\n",
    "    metrics=None,\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    "    steps_per_execution=None,\n",
    "    jit_compile=None,\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b153a1",
   "metadata": {},
   "source": [
    "The important arguments are as follows −\n",
    "\n",
    "- loss function\n",
    "- Optimizer\n",
    "- metrics\n",
    "\n",
    "A sample code to compile the mode is as follows −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef43db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(loss ='mean_squared_error',\n",
    "\n",
    "optimizer ='sgd', metrics =[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7fe51",
   "metadata": {},
   "source": [
    "where,\n",
    "\n",
    "- loss function is set as  **mean\\_squared\\_error**\n",
    "- optimizer is set as  **sgd**\n",
    "- metrics is set as  **metrics.categorical\\_accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fe523",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Models are trained by NumPy arrays using _**fit()**_. \n",
    "\n",
    "The main purpose of this fit function is used to evaluate your model on training. This can be also used for graphing model performance. It has the following syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc71fc-b067-4173-82c9-b0c369599350",
   "metadata": {},
   "source": [
    "```Python\n",
    "Model.fit(\n",
    "    x=None,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    epochs=1,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8279fa-17c0-4a6e-89f4-019c2afb6fe2",
   "metadata": {},
   "source": [
    "Arguments\n",
    "\n",
    "- **X, y**  − It is a tuple to evaluate your data.\n",
    "- **epochs**  − no of times the model is needed to be evaluated during training.\n",
    "- **batch\\_size**  − training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0c4b1-b2b2-451a-9c0d-fadf8368d311",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "\n",
    "Let us take a simple example of numpy random data to use this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01822143",
   "metadata": {},
   "source": [
    "**Create data**\n",
    "\n",
    "Let us create a random data using numpy for x and y with the help of below mentioned command −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.random.random((100,4,8))\n",
    "y_train = np.random.random((100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40c691-b038-49ca-b784-f5ee7087e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44846a7",
   "metadata": {},
   "source": [
    "Now, create random validation data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.random.random((100,4,8))\n",
    "y_val = np.random.random((100,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e918b",
   "metadata": {},
   "source": [
    "****Create model****\n",
    "\n",
    "Let us create simple sequential model −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8172212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe917c5c",
   "metadata": {},
   "source": [
    "**Add layers**\n",
    "\n",
    "Create layers to add to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547fce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# add a sequence of vectors of dimension 16\n",
    "\n",
    "model.add(LSTM(16, return_sequences = True))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee46f2",
   "metadata": {},
   "source": [
    "**compile model**\n",
    "\n",
    "Now model is defined. You can compile using the below command −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\n",
    "loss = 'categorical_crossentropy', \n",
    "    optimizer = 'sgd', \n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc7d56",
   "metadata": {},
   "source": [
    "**Apply fit()**\n",
    "\n",
    "Now we apply _fit()_ function to train our data −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f886c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          batch_size = 32, \n",
    "          epochs = 5, \n",
    "          validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12652268-bcc3-4958-97ae-55ebbe98d738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bcd25f-eda3-43a7-8e83-83c1e834a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250165c-845a-4fd0-8d0e-58fdf60b460c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d2fc12d-f64c-4134-861d-1fc034658e99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset module\n",
    "\n",
    "Before creating a model, we need to choose a problem, need to collect the required data and convert the data to NumPy array. Once data is collected, we can prepare the model and train it by using the collected data. Data collection is one of the most difficult phase of machine learning. Keras provides a special module, datasets to download the online machine learning data for training purposes. It fetches the data from online server, process the data and return the data as training and test set. Let us check the data provided by Keras dataset module. The data available in the module are as follows,\n",
    "\n",
    "- CIFAR10 small image classification\n",
    "- CIFAR100 small image classification\n",
    "- IMDB Movie reviews sentiment classification\n",
    "- Reuters newswire topics classification\n",
    "- MNIST database of handwritten digits\n",
    "- Fashion-MNIST database of fashion articles\n",
    "- Boston housing price regression dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187d12c-85dc-4170-a7c4-e04a9af35e18",
   "metadata": {},
   "source": [
    "In the following two examples, we will use **MNIST database of handwritten digits** and  **Boston Housing** to build two simple MLP for classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc40a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f8463-189d-4151-ae27-dbedd3945a4b",
   "metadata": {},
   "source": [
    "We have learned to create, compile and train the Keras models.\n",
    "\n",
    "Let us apply our learning and create a simple MPL based ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8adf98",
   "metadata": {},
   "source": [
    "### MLP for classification\n",
    "\n",
    "Let us use the **MNIST database of handwritten digits** (or minst) as our input. minst is a collection of 60,000, 28x28 grayscale images. It contains 10 digits. It also contains 10,000 test images.\n",
    "\n",
    "Below code can be used to load the dataset −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test)= keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39765d17",
   "metadata": {},
   "source": [
    "where\n",
    "\n",
    "- **Line 1**  imports  **minst**  from the keras dataset module.\n",
    "- **Line 3**  calls the  **load\\_data**  function, which will fetch the data from online server and return the data as 2 tuples, First tuple, **(x\\_train, y\\_train)** represent the training data with shape, **(number\\_sample, 28, 28)** and its digit label with shape, **(number\\_samples, )**. Second tuple, **(x\\_test, y\\_test)** represent test data with same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f372a",
   "metadata": {},
   "source": [
    "#### Load data and build the model\n",
    "\n",
    "Let us choose a simple multi-layer perceptron (MLP) as represented below and try to create the model using Keras.\n",
    "\n",
    "![](img/Picture2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac0e9b",
   "metadata": {},
   "source": [
    "The core features of the model are as follows −\n",
    "\n",
    "- Input layer consists of 784 values (28 x 28 = 784).\n",
    "- First hidden layer,  **Dense**  consists of 512 neurons and 'relu' activation function.\n",
    "- Second hidden layer,  **Dropout**  has 0.2 as its value.\n",
    "- Third hidden layer, again Dense consists of 512 neurons and 'relu' activation function.\n",
    "- Fourth hidden layer,  **Dropout**  has 0.2 as its value.\n",
    "- Fifth and final layer consists of 10 neurons and 'softmax' activation function.\n",
    "- Use  **categorical\\_crossentropy**  as loss function.\n",
    "- Use **RMSprop()** as Optimizer.\n",
    "- Use  **accuracy**  as metrics.\n",
    "- Use 128 as batch size.\n",
    "- Use 20 as epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a8bd7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step 1 − Import the modules**\n",
    "\n",
    "Let us import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2fcfd",
   "metadata": {},
   "source": [
    "**Step 2 − Load data**\n",
    "\n",
    "Let us import the mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d789d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a20430",
   "metadata": {},
   "source": [
    "**Step 3 − Process the data**\n",
    "\n",
    "Let us change the dataset according to our model, so that it can be feed into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d22207",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512817f",
   "metadata": {},
   "source": [
    "Where\n",
    "\n",
    "- **reshape**  is used to reshape the input from (28, 28) tuple to (784, )\n",
    "- **to\\_categorical**  is used to convert vector to binary matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e329e",
   "metadata": {},
   "source": [
    "**Step 4 − Create the model**\n",
    "\n",
    "Let us create the actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation ='relu', \n",
    "                input_shape =(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation ='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10, activation ='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66f64c",
   "metadata": {},
   "source": [
    "**Step 5 − Compile the model**\n",
    "\n",
    "Let us compile the model using selected loss function, optimizer and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb237a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss ='categorical_crossentropy', \n",
    "              optimizer =RMSprop(),\n",
    "              metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6af8f",
   "metadata": {},
   "source": [
    "**Step 6 − Train the model**\n",
    "\n",
    "Let us train the model using _**fit()**_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd767972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size =128,\n",
    "                    epochs =20,\n",
    "                    verbose =1,\n",
    "                    validation_data =(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ec9b7",
   "metadata": {},
   "source": [
    "Final thoughts\n",
    "\n",
    "We have created the model, loaded the data and also trained the data to the model. We still need to evaluate the model and predict output for unknown input, which we learn in upcoming chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train),(x_test, y_test)= keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(512, activation='relu', input_shape =(784,)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation ='relu')) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10, activation ='softmax'))\n",
    "\n",
    "model.compile(loss ='categorical_crossentropy',\n",
    "              optimizer =RMSprop(),\n",
    "              metrics =['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size =128, \n",
    "                    epochs =20, \n",
    "                    verbose =1,\n",
    "                    validation_data =(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c7b1f6",
   "metadata": {},
   "source": [
    "\n",
    "Let us begin by evaluating the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a4a26",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "Evaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data. Keras model provides a function, evaluate which does the evaluation of the model. It has three main arguments,\n",
    "\n",
    "- Test data\n",
    "- Test data label\n",
    "- verbose - true or false\n",
    "\n",
    "Let us evaluate the model, which we created in the previous section using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c58d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose =0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0526404",
   "metadata": {},
   "source": [
    "\n",
    "The test accuracy is 98.51%. We have created a best model to identify the handwriting digits. \n",
    "\n",
    "On the positive side, we can still scope to improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569e1428",
   "metadata": {},
   "source": [
    "#### Model Prediction\n",
    "\n",
    "_ **Prediction** _ is the final step and our expected outcome of the model generation. Keras provides a method, `predict` to get the prediction of the trained model. The signature of the _predict_ method is as follows,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a86ea",
   "metadata": {},
   "source": [
    "```python \n",
    "predict(x,\n",
    "        batch_size =None,\n",
    "        verbose =0,\n",
    "        steps =None,\n",
    "        callbacks =None,\n",
    "        max_queue_size =10,\n",
    "        workers =1,\n",
    "        use_multiprocessing =False\n",
    "       )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9f0ee",
   "metadata": {},
   "source": [
    "Here, all arguments are optional except the first argument, which refers the unknown input data. The shape should be maintained to get the proper prediction.\n",
    "\n",
    "Let us do prediction for our MPL model created in previous chapter using below code −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ddba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "pred = np.argmax(pred, axis =1)[:5]\n",
    "label = np.argmax(y_test,axis =1)[:5]\n",
    "\n",
    "print(pred)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78316612",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "- **Line 1**  call the predict function using test data.\n",
    "- **Line 2**  gets the first five prediction\n",
    "- **Line 3**  gets the first five labels of the test data.\n",
    "- **Line 5 - 6**  prints the prediction and actual label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a285fd",
   "metadata": {},
   "source": [
    "The output of both array is identical and it indicate that our model predicts correctly the first five images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c25d4",
   "metadata": {},
   "source": [
    "### MLP for regression\n",
    "\n",
    "\n",
    "In this section, let us write a simple MPL based ANN to do regression prediction.\n",
    "\n",
    "Till now, we have only done the classification based prediction. \n",
    "\n",
    "Now, we will try to predict the next possible value by analyzing the previous (continuous) values and its influencing factors.\n",
    "\n",
    "In this example, we build a Regression MPL to predict hourse price and use the **Boston Housing** dataset which is \n",
    " provided by Keras. It represents a collection of housing information in Boston area, each having 13 features.\n",
    "\n",
    "\n",
    "![](img/Picture3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d1bb3",
   "metadata": {},
   "source": [
    "#### Load data and build the model\n",
    "\n",
    "Let us choose a simple multi-layer perceptron (MLP) for regression and create the model using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17f8cd",
   "metadata": {},
   "source": [
    "The core features of the MLP model are as follows −\n",
    "\n",
    "- Input layer consists of (13,) values.\n",
    "- First layer, _Dense_ consists of 64 units and 'relu' activation function with 'normal' kernel initializer.\n",
    "- Second layer, _Dense_ consists of 64 units and 'relu' activation function.\n",
    "- Output layer, _Dense_ consists of 1 unit.\n",
    "- Use  **mse**  as loss function.\n",
    "- Use  **RMSprop**  as Optimizer.\n",
    "- Use  **accuracy**  as metrics.\n",
    "- Use 128 as batch size.\n",
    "- Use 500 as epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e525c7",
   "metadata": {},
   "source": [
    "**Step 1 − Import the modules**\n",
    "\n",
    "Let us import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2504c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78de80",
   "metadata": {},
   "source": [
    "**Step 2 − Load data**\n",
    "\n",
    "Let us import the Boston housing dataset. \n",
    "Below code can be used to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aef647",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f489a",
   "metadata": {},
   "source": [
    "**Step 3 − Process the data**\n",
    "\n",
    "Let us change the dataset according to our model, so that, we can feed into our model. The data can be changed using below code −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = preprocessing.scale(x_train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355be33",
   "metadata": {},
   "source": [
    "Here, we have normalized the training data using  **sklearn.preprocessing.scale**  function. **preprocessing.StandardScaler().fit** function returns a scalar with the normalized mean and standard deviation of the training data, which we can apply to the test data using  **scalar.transform**  function. This will normalize the test data as well with the same setting as that of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4d9cf",
   "metadata": {},
   "source": [
    "**Step 4 − Create the model**\n",
    "\n",
    "Let us create the actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80723fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(64, \n",
    "                kernel_initializer ='normal', \n",
    "                activation ='relu',\n",
    "\n",
    "input_shape =(13,)))\n",
    "\n",
    "model.add(Dense(64, activation ='relu')) \n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cabae",
   "metadata": {},
   "source": [
    "**Step 5 − Compile the model**\n",
    "\n",
    "Let us compile the model using selected loss function, optimizer and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f555fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss ='mse',\n",
    "    optimizer =RMSprop(),\n",
    "    metrics =['mean_absolute_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fa542",
   "metadata": {},
   "source": [
    "**Step 6 − Train the model**\n",
    "\n",
    "Let us train the model using **fit()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train_scaled, y_train,\n",
    "    batch_size=128,\n",
    "    epochs =500,\n",
    "    verbose =1,\n",
    "    validation_split =0.2,\n",
    "    callbacks =[EarlyStopping(monitor ='val_loss', patience =20)]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec21301",
   "metadata": {},
   "source": [
    "Here, we have used callback function,  **EarlyStopping**. The purpose of this callback is to monitor the loss value during each epoch and compare it with previous epoch loss value to find the improvement in the training. If there is no improvement for the  **patience**  times, then the whole process will be stopped.\n",
    "\n",
    "Executing the application will give the below information as output −"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc56e7",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "Evaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data. Keras model provides a function, `evaluate` which does the evaluation of the model. \n",
    "\n",
    "**Step 7 − Evaluate the model**\n",
    "\n",
    "Let us evaluate the model using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_scaled, y_test, verbose =0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf110b",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff0bf5",
   "metadata": {},
   "source": [
    "**Step 8 − Predict**\n",
    "\n",
    "Finally, predict using test data as below −"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test_scaled)\n",
    "\n",
    "print(prediction.flatten())\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543150e7",
   "metadata": {},
   "source": [
    "The output of the above application is as follows −"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12d62e-4d13-4ca4-8ed8-31896608c2d3",
   "metadata": {},
   "source": [
    "The output of both array have around 10-30% difference and it indicate our model predicts with reasonable range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ac75d-f5e0-4189-95a7-893596c5ee0e",
   "metadata": {},
   "source": [
    "> Keras - Time Series Prediction using LSTM RNN\n",
    "\n",
    "> Keras - Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9153e",
   "metadata": {},
   "source": [
    "**Acknowledgment:**\n",
    "\n",
    "> This tutorial is adapted from the [Keras Quick Guide](https://www.tutorialspoint.com/keras/keras\\_quick\\_guide.htm) authored by  [Tutorialpoint](https://www.tutorialspoint.com). Please visit tutorial point for learning materials on technical and non-technical subjects.\n",
    "> In addition, this tutorial include examples from [Keras.io](https://keras.io) website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf622ae-0b8c-4e7f-8774-2f2a726fb107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.14999389648438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
