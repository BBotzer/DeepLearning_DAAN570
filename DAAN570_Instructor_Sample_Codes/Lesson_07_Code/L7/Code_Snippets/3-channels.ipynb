{"cells":[{"cell_type":"markdown","metadata":{"origin_pos":0},"source":["# Multiple Input and Multiple Output Channels\n","\n","## Multiple Input Channels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":4,"tab":["tensorflow"]},"outputs":[],"source":["import tensorflow as tf\n","from dl import tensorflow as dl\n","\n","def corr2d_multi_in(X, K):\n","    # First, iterate through the 0th dimension (channel dimension) of `X` and\n","    # `K`. Then, add them together\n","    return tf.reduce_sum([dl.corr2d(x, k) for x, k in zip(X, K)], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":6,"tab":["tensorflow"]},"outputs":[],"source":["X = tf.constant([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n","                 [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n","K = tf.constant([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n","\n","corr2d_multi_in(X, K)"]},{"cell_type":"markdown","metadata":{"origin_pos":7},"source":["## Multiple Output Channels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":8,"tab":["tensorflow"]},"outputs":[],"source":["def corr2d_multi_in_out(X, K):\n","    # Iterate through the 0th dimension of `K`, and each time, perform\n","    # cross-correlation operations with input `X`. All of the results are\n","    # stacked together\n","    return tf.stack([corr2d_multi_in(X, k) for k in K], 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":10,"tab":["tensorflow"]},"outputs":[],"source":["K = tf.stack((K, K + 1, K + 2), 0)\n","K.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":12,"tab":["tensorflow"]},"outputs":[],"source":["corr2d_multi_in_out(X, K)"]},{"cell_type":"markdown","metadata":{"origin_pos":13},"source":["## $1\\times 1$ Convolutional Layer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":14,"tab":["tensorflow"]},"outputs":[],"source":["def corr2d_multi_in_out_1x1(X, K):\n","    c_i, h, w = X.shape\n","    c_o = K.shape[0]\n","    X = tf.reshape(X, (c_i, h * w))\n","    K = tf.reshape(K, (c_o, c_i))\n","    # Matrix multiplication in the fully-connected layer\n","    Y = tf.matmul(K, X)\n","    return tf.reshape(Y, (c_o, h, w))"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":17,"tab":["tensorflow"]},"outputs":[],"source":["X = tf.random.normal((3, 3, 3), 0, 1)\n","K = tf.random.normal((2, 3, 1, 1), 0, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"origin_pos":18,"tab":["tensorflow"]},"outputs":[],"source":["Y1 = corr2d_multi_in_out_1x1(X, K)\n","Y2 = corr2d_multi_in_out(X, K)\n","assert float(tf.reduce_sum(tf.abs(Y1 - Y2))) < 1e-6"]},{"cell_type":"markdown","metadata":{"origin_pos":19},"source":["\n","\n","## Exercises (Optional)\n","\n","\n","1. Assume that we have two convolution kernels of size $k_1$ and $k_2$, respectively (with no nonlinearity in between).\n","    1. Prove that the result of the operation can be expressed by a single convolution.\n","    1. What is the dimensionality of the equivalent single convolution?\n","    1. Is the converse true?\n","1. Assume an input of shape $c_i\\times h\\times w$ and a convolution kernel of shape $c_o\\times c_i\\times k_h\\times k_w$, padding of $(p_h, p_w)$, and stride of $(s_h, s_w)$.\n","    1. What is the computational cost (multiplications and additions) for the forward propagation?\n","    1. What is the memory footprint?\n","    1. What is the memory footprint for the backward computation?\n","    1. What is the computational cost for the backpropagation?\n","1. By what factor does the number of calculations increase if we double the number of input channels $c_i$ and the number of output channels $c_o$? What happens if we double the padding?\n","1. If the height and width of a convolution kernel is $k_h=k_w=1$, what is the computational complexity of the forward propagation?\n","1. Are the variables `Y1` and `Y2` in the last example of this section exactly the same? Why?\n","1. How would you implement convolutions using matrix multiplication when the convolution window is not $1\\times 1$?\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":true},"deepnote_notebook_id":"77fd30ba-bdda-47ed-9655-e54dd250c2f5"},"nbformat":4,"nbformat_minor":4}