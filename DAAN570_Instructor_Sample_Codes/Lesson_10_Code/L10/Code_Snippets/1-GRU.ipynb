{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Gated Recurrent Units (GRU)\n",
    "\n",
    "\n",
    "\n",
    "## Implementation from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dl import tensorflow as dl\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = dl.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "### Initializing Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return tf.random.normal(shape=shape, stddev=0.01, mean=0,\n",
    "                                dtype=tf.float32)\n",
    "\n",
    "    def three():\n",
    "        return (tf.Variable(normal((num_inputs, num_hiddens)),\n",
    "                            dtype=tf.float32),\n",
    "                tf.Variable(normal((num_hiddens, num_hiddens)),\n",
    "                            dtype=tf.float32),\n",
    "                tf.Variable(tf.zeros(num_hiddens), dtype=tf.float32))\n",
    "\n",
    "    W_xz, W_hz, b_z = three()  # Update gate parameters\n",
    "    W_xr, W_hr, b_r = three()  # Reset gate parameters\n",
    "    W_xh, W_hh, b_h = three()  # Candidate hidden state parameters\n",
    "    # Output layer parameters\n",
    "    W_hq = tf.Variable(normal((num_hiddens, num_outputs)), dtype=tf.float32)\n",
    "    b_q = tf.Variable(tf.zeros(num_outputs), dtype=tf.float32)\n",
    "    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "### Defining the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens):\n",
    "    return (tf.zeros((batch_size, num_hiddens)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 15,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "def gru(inputs, state, params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        X = tf.reshape(X, [-1, W_xh.shape[0]])\n",
    "        Z = tf.sigmoid(tf.matmul(X, W_xz) + tf.matmul(H, W_hz) + b_z)\n",
    "        R = tf.sigmoid(tf.matmul(X, W_xr) + tf.matmul(H, W_hr) + b_r)\n",
    "        H_tilda = tf.tanh(tf.matmul(X, W_xh) + tf.matmul(R * H, W_hh) + b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilda\n",
    "        Y = tf.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return tf.concat(outputs, axis=0), (H,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "### Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, device_name = len(\n",
    "    vocab), 256, dl.try_gpu()._device_name\n",
    "# defining tensorflow training strategy\n",
    "strategy = tf.distribute.OneDeviceStrategy(device_name)\n",
    "num_epochs, lr = 500, 1\n",
    "with strategy.scope():\n",
    "    model = dl.RNNModelScratch(len(vocab), num_hiddens, init_gru_state, gru,\n",
    "                                get_params)\n",
    "\n",
    "dl.train_dl(model, train_iter, vocab, lr, num_epochs, strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "## Concise Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "gru_cell = tf.keras.layers.GRUCell(num_hiddens,\n",
    "                                   kernel_initializer='glorot_uniform')\n",
    "gru_layer = tf.keras.layers.RNN(gru_cell, time_major=True,\n",
    "                                return_sequences=True, return_state=True)\n",
    "\n",
    "device_name = dl.try_gpu()._device_name\n",
    "strategy = tf.distribute.OneDeviceStrategy(device_name)\n",
    "with strategy.scope():\n",
    "    model = dl.RNNModel(gru_layer, vocab_size=len(vocab))\n",
    "\n",
    "dl.train_dl(model, train_iter, vocab, lr, num_epochs, strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "\n",
    "## Exercises (optional)\n",
    "\n",
    "1. Assume that we only want to use the input at time step $t'$ to predict the output at time step $t > t'$. What are the best values for the reset and update gates for each time step?\n",
    "1. Adjust the hyperparameters and analyze the their influence on running time, perplexity, and the output sequence.\n",
    "1. Compare runtime, perplexity, and the output strings for `rnn.RNN` and `rnn.GRU` implementations with each other.\n",
    "1. What happens if you implement only parts of a GRU, e.g., with only a reset gate or only an update gate?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
