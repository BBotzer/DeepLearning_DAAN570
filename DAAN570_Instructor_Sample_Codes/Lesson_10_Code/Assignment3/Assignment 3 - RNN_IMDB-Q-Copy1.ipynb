{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RNNs to classify sentiment on IMDB data\n",
    "\n",
    "In this assignment,you will train three types of RNNs:  \"vanilla\" RNN, LSTM and GRU to predict the sentiment on IMDB reviews.  \n",
    "\n",
    "Keras provides a convenient interface to load the data and immediately encode the words into integers (based on the most common words). \n",
    "This will save you a lot of the drudgery that is usually involved when working with raw text.\n",
    "\n",
    "The IMDB is  data consists of 25000 training sequences and 25000 test sequences. \n",
    "The outcome is binary (positive/negative) and both outcomes are equally represented in both the training and the test set.\n",
    "\n",
    "\n",
    "Walk through the followinng steps to prepare the data and the building of an RNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btb51\\anaconda3\\envs\\DAAN570_tf_updated\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/80 [00:00<?, ? MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]B/s]\u001b[A\n",
      "Dl Size...:   1%|▏         | 1/80 [00:00<01:14,  1.07 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Size...:   2%|▎         | 2/80 [00:01<00:36,  2.12 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Size...:   5%|▌         | 4/80 [00:01<00:23,  3.20 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Size...:   9%|▉         | 7/80 [00:01<00:12,  5.80 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]B/s]\u001b[A\n",
      "Dl Size...:  11%|█▏        | 9/80 [00:01<00:07,  9.45 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  14%|█▍        | 11/80 [00:01<00:06, 10.91 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  16%|█▋        | 13/80 [00:01<00:05, 12.16 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  19%|█▉        | 15/80 [00:01<00:04, 13.20 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  21%|██▏       | 17/80 [00:02<00:04, 14.03 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  24%|██▍       | 19/80 [00:02<00:04, 14.62 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  26%|██▋       | 21/80 [00:02<00:03, 15.22 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  29%|██▉       | 23/80 [00:02<00:03, 16.30 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  31%|███▏      | 25/80 [00:02<00:03, 16.53 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  34%|███▍      | 27/80 [00:02<00:03, 16.53 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  36%|███▋      | 29/80 [00:02<00:02, 17.04 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:02<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  40%|████      | 32/80 [00:02<00:03, 14.52 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  42%|████▎     | 34/80 [00:03<00:02, 15.64 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  45%|████▌     | 36/80 [00:03<00:02, 14.93 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  48%|████▊     | 38/80 [00:03<00:02, 14.54 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  50%|█████     | 40/80 [00:03<00:02, 13.70 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  52%|█████▎    | 42/80 [00:03<00:02, 13.43 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  55%|█████▌    | 44/80 [00:03<00:02, 12.32 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  57%|█████▊    | 46/80 [00:04<00:03, 11.02 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  59%|█████▉    | 47/80 [00:04<00:03,  9.01 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  60%|██████    | 48/80 [00:04<00:03,  8.58 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  61%|██████▏   | 49/80 [00:04<00:03,  8.28 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  62%|██████▎   | 50/80 [00:04<00:03,  8.14 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  64%|██████▍   | 51/80 [00:04<00:03,  8.03 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  65%|██████▌   | 52/80 [00:05<00:03,  7.72 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  66%|██████▋   | 53/80 [00:05<00:03,  7.74 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  68%|██████▊   | 54/80 [00:05<00:03,  7.75 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  69%|██████▉   | 55/80 [00:05<00:03,  7.83 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  70%|███████   | 56/80 [00:05<00:03,  7.85 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  71%|███████▏  | 57/80 [00:05<00:02,  7.91 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  72%|███████▎  | 58/80 [00:05<00:02,  7.93 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  74%|███████▍  | 59/80 [00:05<00:02,  7.92 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  75%|███████▌  | 60/80 [00:06<00:02,  7.74 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  76%|███████▋  | 61/80 [00:06<00:02,  7.98 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  78%|███████▊  | 62/80 [00:06<00:02,  7.89 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  79%|███████▉  | 63/80 [00:06<00:02,  7.87 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  80%|████████  | 64/80 [00:06<00:02,  7.76 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  81%|████████▏ | 65/80 [00:06<00:01,  7.81 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  82%|████████▎ | 66/80 [00:06<00:01,  7.85 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  84%|████████▍ | 67/80 [00:06<00:01,  7.86 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  85%|████████▌ | 68/80 [00:07<00:01,  7.81 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  86%|████████▋ | 69/80 [00:07<00:01,  7.85 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  88%|████████▊ | 70/80 [00:07<00:01,  7.57 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  89%|████████▉ | 71/80 [00:07<00:01,  8.01 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  90%|█████████ | 72/80 [00:07<00:00,  8.47 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  91%|█████████▏| 73/80 [00:07<00:00,  8.33 MiB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  92%|█████████▎| 74/80 [00:07<00:00,  8.18 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  94%|█████████▍| 75/80 [00:07<00:00,  8.09 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  95%|█████████▌| 76/80 [00:08<00:00,  7.93 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  96%|█████████▋| 77/80 [00:08<00:00,  7.91 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  98%|█████████▊| 78/80 [00:08<00:00,  8.00 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Size...:  99%|█████████▉| 79/80 [00:08<00:00,  8.49 MiB/s]\u001b[A\n",
      "Dl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]iB/s]\u001b[A\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:08<00:00,  8.89s/ url]\n",
      "Dl Size...: 100%|██████████| 80/80 [00:08<00:00,  9.00 MiB/s]\u001b[A\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:08<00:00,  8.90s/ url]\n",
      "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 1 examples [00:02,  2.86s/ examples]\u001b[A\n",
      "Generating train examples...: 4902 examples [00:03, 1632.05 examples/s]\u001b[A\n",
      "Generating train examples...: 9246 examples [00:04, 2505.39 examples/s]\u001b[A\n",
      "Generating train examples...: 13468 examples [00:05, 3045.55 examples/s]\u001b[A\n",
      "Generating train examples...: 18778 examples [00:06, 3748.50 examples/s]\u001b[A\n",
      "Generating train examples...: 23708 examples [00:07, 4110.22 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-train.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-train.tfrecord*...:  21%|██        | 5256/25000 [00:00<00:00, 52040.43 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-train.tfrecord*...:  46%|████▌     | 11403/25000 [00:00<00:00, 57564.24 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-train.tfrecord*...:  69%|██████▉   | 17297/25000 [00:00<00:00, 57927.04 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-train.tfrecord*...:  92%|█████████▏| 23091/25000 [00:00<00:00, 52372.65 examples/s]\u001b[A\n",
      "Generating splits...:  33%|███▎      | 1/3 [00:13<00:27, 13.61s/ splits]                                                                                                                    \u001b[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 1939 examples [00:01, 1938.99 examples/s]\u001b[A\n",
      "Generating test examples...: 7111 examples [00:02, 3838.51 examples/s]\u001b[A\n",
      "Generating test examples...: 12703 examples [00:03, 4638.94 examples/s]\u001b[A\n",
      "Generating test examples...: 17683 examples [00:04, 4773.02 examples/s]\u001b[A\n",
      "Generating test examples...: 22640 examples [00:05, 4837.61 examples/s]\u001b[A\n",
      "                                                                       \u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-test.tfrecord*...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-test.tfrecord*...:   0%|          | 1/25000 [00:00<52:55,  7.87 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-test.tfrecord*...:  25%|██▌       | 6338/25000 [00:00<00:00, 33378.24 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-test.tfrecord*...:  50%|████▉     | 12407/25000 [00:00<00:00, 45100.66 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-test.tfrecord*...:  75%|███████▌  | 18829/25000 [00:00<00:00, 52170.58 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-test.tfrecord*...: 100%|██████████| 25000/25000 [00:00<00:00, 24540.19 examples/s]\u001b[A\n",
      "Generating splits...:  67%|██████▋   | 2/3 [00:26<00:13, 13.47s/ splits]                                                                                                                   \u001b[A\n",
      "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 1 examples [00:04,  4.83s/ examples]\u001b[A\n",
      "Generating unsupervised examples...: 5628 examples [00:05, 1285.40 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 11221 examples [00:06, 2345.15 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 16719 examples [00:07, 3165.07 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 22297 examples [00:08, 3818.68 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 27790 examples [00:09, 4285.76 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 33013 examples [00:10, 4381.68 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 38389 examples [00:11, 4661.59 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 44052 examples [00:12, 4948.76 examples/s]\u001b[A\n",
      "Generating unsupervised examples...: 49350 examples [00:14, 4700.52 examples/s]\u001b[A\n",
      "                                                                               \u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:   7%|▋         | 3514/50000 [00:00<00:01, 34792.05 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  20%|██        | 10109/50000 [00:00<00:00, 52736.42 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  33%|███▎      | 16607/50000 [00:00<00:00, 58033.51 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  46%|████▋     | 23162/50000 [00:00<00:00, 60744.93 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  59%|█████▉    | 29598/50000 [00:00<00:00, 62040.19 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  72%|███████▏  | 36161/50000 [00:00<00:00, 63042.24 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  85%|████████▍ | 42466/50000 [00:00<00:00, 63044.44 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete026ID8\\imdb_reviews-unsupervised.tfrecord*...:  98%|█████████▊| 48771/50000 [00:00<00:00, 55633.31 examples/s]\u001b[A\n",
      "                                                                                                                                                                                                   \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\btb51\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "b'Zero Day leads you to think, even re-think why two'\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I am not using this dataset loader.  I am using the one found above from the \n",
    "tensorflow_datasets library since I can Prefetch the dataset\n",
    "\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\",\n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "# set path to dataset\n",
    "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "classes = [\"pos\", \"neg\"]\n",
    "train_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
    ")\n",
    "test_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
    ")\n",
    "\n",
    "x_train = np.array(train_data.data)\n",
    "y_train = np.array(train_data.target)\n",
    "x_test = np.array(test_data.data)\n",
    "y_test = np.array(test_data.target)\n",
    "\n",
    "print(x_train.shape)  # (25000,)\n",
    "print(y_train.shape)  # (25000, 1)\n",
    "print(x_train[0][:50])  # this film was just brilliant casting\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Use the `imdb.load_data()` to load in the data \n",
    "\n",
    "2- Specify the maximum length of a sequence to 30 words and the pick the 2000 most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2000\n",
    "\n",
    "encoder = tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Check that the number of sequences in train and test datasets are equal (default split):\n",
    "    \n",
    "Expected output:\n",
    "- `x_train = 25000 train sequences`\n",
    "\n",
    "- `x_test = 25000 test sequences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Pad (or truncate) the sequences so that they are of the maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- After padding or truncating, check the dimensionality of x_train and x_test.\n",
    "\n",
    "Expected output:\n",
    "- `x_train shape: (25000, 30)`\n",
    "- `x_test shape: (25000, 30)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras layers for (Vanilla) RNNs\n",
    "\n",
    "In this step, you will not use pre-trained word vectors, Instead you will learn an embedding as part of the  the Vanilla) RNNs network  Neural Network. \n",
    "\n",
    "In the Keras API documentation, the Embedding Layer and the SimpleRNN Layer have the following syntax:\n",
    "\n",
    "### Embedding Layer\n",
    "`keras.layers.embeddings.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)`\n",
    "\n",
    "- This layer maps each integer into a distinct (dense) word vector of length `output_dim`.\n",
    "- Can think of this as learning a word vector embedding \"on the fly\" rather than using an existing mapping (like GloVe)\n",
    "- The `input_dim` should be the size of the vocabulary.\n",
    "- The `input_length` specifies the length of the sequences that the network expects.\n",
    "\n",
    "### SimpleRNN Layer\n",
    "`keras.layers.recurrent.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)`\n",
    "\n",
    "- This is the basic RNN, where the output is also fed back as the \"hidden state\" to the next iteration.\n",
    "- The parameter `units` gives the dimensionality of the output (and therefore the hidden state).  Note that typically there will be another layer after the RNN mapping the (RNN) output to the network output.  So we should think of this value as the desired dimensionality of the hidden state and not necessarily the desired output of the network.\n",
    "- Recall that there are two sets of weights, one for the \"recurrent\" phase and the other for the \"kernel\" phase.  These can be configured separately in terms of their initialization, regularization, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Build the RNN with three layers: \n",
    "- The SimpleRNN layer with 5 neurons and initialize its kernel with stddev=0.001\n",
    "\n",
    "- The Embedding layer and initialize it by setting the word embedding dimension to 50. This means that this layer takes each integer in the sequence and embeds it in a 50-dimensional vector.\n",
    "\n",
    "-  The output layer has the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- How many parameters have the embedding layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Train the network with the RMSprop with learning rate of .0001 and epochs=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9- Plot the loss and accuracy metrics during the training and interpret the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10- Check the accuracy and the loss of your models on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning The Vanilla RNN Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11- Prepare the data to use sequences of length 80 rather than length 30 and retrain your model.  Did it improve the performance?\n",
    "\n",
    "12- Try different values of the  maximum length of a sequence (\"max_features\").  Can you improve the performance?\n",
    "\n",
    "13- Try smaller and larger sizes of the RNN hidden dimension.  How does it affect the model performance?  How does it affect the run time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM and GRU networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "14- Build LSTM and GRU networks and compare their performance (accuracy and execution time) with the SimpleRNN. What is your conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
