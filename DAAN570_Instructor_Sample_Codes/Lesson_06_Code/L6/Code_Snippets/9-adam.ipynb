{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Adam\n",
    "\n",
    "## The Algorithm\n",
    "\n",
    "One of the key components of Adam is that it uses exponential weighted moving averages (also known as leaky averaging) to obtain an estimate of both the momentum and also the second moment of the gradient. That is, it uses the state variables\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\mathbf{v}_t & \\leftarrow \\beta_1 \\mathbf{v}_{t-1} + (1 - \\beta_1) \\mathbf{g}_t, \\\\\n",
    "    \\mathbf{s}_t & \\leftarrow \\beta_2 \\mathbf{s}_{t-1} + (1 - \\beta_2) \\mathbf{g}_t^2.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Here $\\beta_1$ and $\\beta_2$ are nonnegative weighting parameters. Common choices for them are $\\beta_1 = 0.9$ and $\\beta_2 = 0.999$. That is, the variance estimate moves *much more slowly* than the momentum term.\n",
    "\n",
    "\n",
    "Note that if we initialize $\\mathbf{v}_0 = \\mathbf{s}_0 = 0$ we have a significant amount of bias initially towards smaller values. This can be addressed by using the fact that $\\sum_{i=0}^t \\beta^i = \\frac{1 - \\beta^t}{1 - \\beta}$ to re-normalize terms. Correspondingly the normalized state variables are given by \n",
    "\n",
    "\n",
    "## Implementation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from dl import tensorflow as dl\n",
    "\n",
    "\n",
    "def init_adam_states(feature_dim):\n",
    "    v_w = tf.Variable(tf.zeros((feature_dim, 1)))\n",
    "    v_b = tf.Variable(tf.zeros(1))\n",
    "    s_w = tf.Variable(tf.zeros((feature_dim, 1)))\n",
    "    s_b = tf.Variable(tf.zeros(1))\n",
    "    return ((v_w, s_w), (v_b, s_b))\n",
    "\n",
    "def adam(params, grads, states, hyperparams):\n",
    "    beta1, beta2, eps = 0.9, 0.999, 1e-6\n",
    "    for p, (v, s), grad in zip(params, states, grads):\n",
    "        v[:].assign(beta1 * v  + (1 - beta1) * grad)\n",
    "        s[:].assign(beta2 * s + (1 - beta2) * tf.math.square(grad))\n",
    "        v_bias_corr = v / (1 - beta1 ** hyperparams['t'])\n",
    "        s_bias_corr = s / (1 - beta2 ** hyperparams['t'])\n",
    "        p[:].assign(p - hyperparams['lr'] * v_bias_corr  \n",
    "                    / tf.math.sqrt(s_bias_corr) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 5,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "data_iter, feature_dim = dl.get_data_ch11(batch_size=10)\n",
    "dl.train_ch11(adam, init_adam_states(feature_dim), {\n",
    "    'lr': 0.01,\n",
    "    't': 1}, data_iter, feature_dim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = tf.keras.optimizers.Adam\n",
    "dl.train_concise_ch11(trainer, {'learning_rate': 0.01}, data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Adjust the learning rate and observe and analyze the experimental results.\n",
    "1. Can you rewrite momentum and second moment updates such that it does not require bias correction?\n",
    "1. Why do you need to reduce the learning rate $\\eta$ as we converge?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
