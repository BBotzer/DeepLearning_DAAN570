{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "922ad467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from keras.metrics import AUC\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e09ce304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_build():\n",
    "    '''\n",
    "    It seems that all of the images have different dimensions.\n",
    "    I will use the resize_with_pad to push everything to the largest m x n dim,\n",
    "    and then I will pool down from there with the goal of the padding \n",
    "    pixels falling out in the CNN.\n",
    "    '''\n",
    "    image_h = 500\n",
    "    image_w = 500\n",
    "    batch_size = 16  #GPU Saturated and memory issues if I go to 32...\n",
    "\n",
    "    # location on disk of the image data\n",
    "    loc = 'C:/Users/btb51/Documents/GitHub/DeepLearning_DAAN570/DAAN570_Instructor_Sample_Codes/Lesson_08_Code/Assignment2_ZooClassifier/Zoo Classifier project - images/images'\n",
    "\n",
    "    #datasets will be a tuple of the train and validation data\n",
    "    train_ds, val_ds = image_dataset_from_directory(loc,\n",
    "                                  batch_size=batch_size,\n",
    "                                  image_size = (image_h,image_w),  # set as largest dims\n",
    "                                  shuffle = True,\n",
    "                                  seed = 570,\n",
    "                                  validation_split = 0.2,\n",
    "                                  subset = 'both')\n",
    "\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb3f1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 3 classes.\n",
      "Using 2400 files for training.\n",
      "Using 600 files for validation.\n",
      "['cats', 'dogs', 'panda'] 3\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = data_build()\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(class_names, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "981e71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_cnn(num_classes):\n",
    "    \n",
    "    #Build a Generic CNN with a set number of classes as the classifing output\n",
    "    \n",
    "    net = Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(500, 500, 3)),\n",
    "    tf.keras.layers.Conv2D(16,3,padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation= 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3486619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_net = working_cnn(num_classes)\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "working_net.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "447198f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_9 (Rescaling)     (None, 500, 500, 3)       0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 500, 500, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 250, 250, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 250, 250, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 125, 125, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 62, 62, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               31490176  \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,514,147\n",
      "Trainable params: 31,514,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "working_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f9e94ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.7447 - accuracy: 0.6317 - val_loss: 0.7094 - val_accuracy: 0.6383\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 0.5034 - accuracy: 0.7842 - val_loss: 0.9030 - val_accuracy: 0.6117\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "history_working = working_net.fit(train_ds,\n",
    "                           validation_data=val_ds,\n",
    "                           epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c9aa5",
   "metadata": {},
   "source": [
    "# Other setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529d08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cnn(num_classes):\n",
    "    \n",
    "    #Build a Generic CNN with a set number of classes as the classifing output\n",
    "    \n",
    "    net = Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(500, 500, 3)),\n",
    "    tf.keras.layers.Conv2D(16,3,padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation= 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'softmax'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c512305",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_net = softmax_cnn(num_classes)\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) #This should be true since I didn't specify softmax\n",
    "metrics = ['accuracy']\n",
    "\n",
    "softmax_net.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8832383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 500, 500, 3)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 500, 500, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 250, 250, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 250, 250, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 125, 125, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               31490176  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,514,147\n",
      "Trainable params: 31,514,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "softmax_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43914af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 1.1432 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history_softmax = softmax_net.fit(train_ds,\n",
    "                           validation_data=val_ds,\n",
    "                           epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a493c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax2_cnn(num_classes):\n",
    "    \n",
    "    #Build a Generic CNN with a set number of classes as the classifing output\n",
    "    \n",
    "    net = Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(500, 500, 3)),\n",
    "    tf.keras.layers.Conv2D(16,3,padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation= 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'softmax'),\n",
    "    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a2aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax2_net = softmax_cnn(num_classes)\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "softmax2_net.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ffeb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 500, 500, 3)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 500, 500, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 250, 250, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 250, 250, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 125, 125, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               31490176  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,514,147\n",
      "Trainable params: 31,514,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "softmax2_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f40cd03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 [==============================] - 16s 99ms/step - loss: 1.1444 - accuracy: 0.3321 - val_loss: 1.0986 - val_accuracy: 0.3367\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 1.0986 - accuracy: 0.3325 - val_loss: 1.0986 - val_accuracy: 0.3367\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 1.0986 - accuracy: 0.3325 - val_loss: 1.0986 - val_accuracy: 0.3367\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 1.0986 - accuracy: 0.3325 - val_loss: 1.0986 - val_accuracy: 0.3367\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 15s 97ms/step - loss: 1.0986 - accuracy: 0.3325 - val_loss: 1.0986 - val_accuracy: 0.3367\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "history_softmax2 = softmax2_net.fit(train_ds,\n",
    "                           validation_data=val_ds,\n",
    "                           epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f58dc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_end_cnn(num_classes):\n",
    "    \n",
    "    #Build a Generic CNN with a set number of classes as the classifing output\n",
    "    \n",
    "    net = Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(500, 500, 3)),\n",
    "    tf.keras.layers.Conv2D(16,3,padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation= 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53030d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_end_net = softmax_cnn(num_classes)\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "softmax_end_net.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1410eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_5 (Rescaling)     (None, 500, 500, 3)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 500, 500, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 250, 250, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 250, 250, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 125, 125, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 62, 62, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               31490176  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,514,147\n",
      "Trainable params: 31,514,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "softmax_end_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cf01d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 [==============================] - 16s 103ms/step - loss: 1.1929 - accuracy: 0.3292 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 18s 119ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 18s 117ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 19s 126ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "history_softmax_end = softmax_end_net.fit(train_ds,\n",
    "                           validation_data=val_ds,\n",
    "                           epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa460a7",
   "metadata": {},
   "source": [
    "# Binary Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa91452",
   "metadata": {},
   "source": [
    "There is a new data import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8576f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import concatenate\n",
    "from keras.metrics import AUC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8baff7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_model():\n",
    "    \n",
    "    #single hidden layer of 12 nodes\n",
    "    model_input = Input(shape=(8,), name='data_in')\n",
    "    hidden_layer_1 = Dense(units=12, activation='relu', name='HL_1')(model_input)\n",
    "    model_out = Dense(1, activation='softmax', name='data_out')(hidden_layer_1)\n",
    "    \n",
    "    #create the model by linking inputs and outputs through Keras functional API\n",
    "    model = Model(inputs=model_input, outputs=model_out, name='Diabetes')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f670a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'C:\\\\Users\\\\btb51\\\\Documents\\\\GitHub\\\\DeepLearning_DAAN570\\\\DAAN570_Instructor_Sample_Codes\\\\Lesson_06_Code\\\\archive\\\\diabetes.csv'\n",
    "\n",
    "file = \"C:/Users/btb51/Documents/GitHub/DeepLearning_DAAN570/DAAN570_Instructor_Sample_Codes/Lesson_06_Code/Assignment_01/archive/diabetes.csv\"\n",
    "data = pd.read_csv(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c86c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x: 506\n",
      "Length of y: 506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Turn missing values to NANs with the exception of pregnacies\n",
    "data[\"BloodPressure\"].replace(to_replace=0, value=np.NAN, inplace=True)\n",
    "data[\"SkinThickness\"].replace(to_replace=0, value=np.NAN, inplace=True)\n",
    "data[\"Insulin\"].replace(to_replace=0, value=np.NAN, inplace=True)\n",
    "\n",
    "#It may be beneficial to_replace with the average of the column if the zeros\n",
    "#push values\n",
    "\n",
    "#drop the duplicates keeping the first instance of any dups\n",
    "data = data.drop_duplicates(keep='first')\n",
    "\n",
    "#Check for outliers (keep anything where all data cols are within 3 std dev)\n",
    "data = data[(np.abs(stats.zscore(data, nan_policy='omit')) < 3).all(axis=1)]\n",
    "\n",
    "#Deal with the class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#splice data\n",
    "y = data.iloc[:, 8]\n",
    "x = data.iloc[:,:8]\n",
    "\n",
    "#make the SMOTE object\n",
    "oversample = SMOTE()\n",
    "\n",
    "#Restore balance\n",
    "x, y = oversample.fit_resample(x,y)\n",
    "\n",
    "#Check the balance\n",
    "print(\"Length of x: \" + str(len(x)))\n",
    "print(\"Length of y: \" + str(len(y)))\n",
    "\n",
    "\n",
    "#use minmaxscaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "data_x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71ad3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, y, test_size=0.25,\n",
    "                                                    random_state=570)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fcf1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_net = binary_model()\n",
    "\n",
    "#USING RMSProp\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "bi_loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "\n",
    "metric = [tf.keras.metrics.BinaryAccuracy(),\n",
    "          tf.keras.metrics.FalsePositives(),\n",
    "          tf.keras.metrics.AUC(curve='ROC')]\n",
    "\n",
    "binary_net.compile(optimizer=optimizer, loss=bi_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcf57414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6929 - accuracy: 0.4934\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.4934\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6879 - accuracy: 0.4934\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6865 - accuracy: 0.4934\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6851 - accuracy: 0.4934\n"
     ]
    }
   ],
   "source": [
    "history_binary = binary_net.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb17802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
